# GAP and CAM

#### GAP 全局平均池化层 Global Average Pooling Layer

第一个提出 GAP 这个想法的，是一篇叫做《Network in Network》的论文。
这篇论文发现用 GAP 代替全连接层，不仅可以降低维度，防止过拟合，减少大量参数，网络的性能也很不错。

如果我们使用 GAP 来代替 FC，优点是最小化参数数量的同时保持高性能，结构变得简单，也避免了过拟合。
但是缺点是和 FC 相比，GAP 收敛速度较慢。

虽然这个 GAP 不是新的技术，但是在论文《Learning Deep Features for Discriminative Localization 》中，他们发现了 GAP 的一个作用，能保留空间信息并且定位（localization）
尽管在图像级标签上进行了训练，它仍能够区分判别图像区域。并且在许多任务中它都可以定位判别图像区域，尽管只是训练基于解决分类任务。

#### CAM（类激活映射）

那么什么是类激活映射呢？
CAM 是一个帮助我们可视化 CNN 的工具。使用 CAM，我们可以清楚的观察到，网络关注图片的哪块区域。
比如，我们的网络识别出这两幅图片，一个是在刷牙，一个是在砍树。
通过 CAM 这个工具，我们可以清楚的看到网络关注图片的哪一部分，根据哪一部分得到的这个结果。

CAM 基于分类，所以被激活的区域是根据分类决定的，即同一个特征图，只更新不同的权重。
所以即使我们使用同一张 input，就像下面这个例子。

#### CAM 的缺陷

这项技术非常有用但是存在一些缺陷的。首先我们必须改变网络结构，例如把全连接层改成全局平均池化层，这不利于训练。
第二是这是基于分类问题的一种可视化技术，用于回归问题可能就没有这么好的效果。

为了解决第一个问题，2017 年出现了一种改进的技术叫 Grad-CAM，Grad-CAM 可以不改变网络结构进行可视化，详见这篇论文《Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization》 (2017 ICCV)。

#### CAM 的应用

- 弱标记图像中定位比较抽象的概念
- 弱监督文字检测，它可以关注文字部分即使网络没有训练过文字或者任何注释框
- 关于视觉问答，我们可以看到网络关注答案区域
- 我们对比模型，选择一个更合适的结构
- CAM 使得弱监督学习发展成为可能，可以慢慢减少对人工标注的依赖，能降低网络训练的成本




## 参考

- [浅谈 Class Activation Mapping（CAM）](https://zhuanlan.zhihu.com/p/51631163)