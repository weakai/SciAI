---
title: 不确定度
---

## Intro

不确定性度量反映的是一个随机变量的离散程度（dispersion）。换句话说，这是一个标量，反应了一个随机变量有多「随机」。在金融领域，这通常被称为「风险」。

不确定性不是某种单一形式，因为衡量离散程度的方法有很多：标准差、方差、风险值（VaR）和熵都是合适的度量。但是，要记住一点：单个标量数值不能描绘「随机性」的整体图景，因为这需要传递整个随机变量本身才行！

尽管如此，为了优化和比较，将随机性压缩成单个数值仍然是有用的。总之要记住，「越高的不确定性」往往被视为「更糟糕」（除了在模拟强化学习实验中）。

### **不确定性的类型** 

![](https://image.jiqizhixin.com/uploads/editor/c26317de-f528-4ba2-8e83-680f93cf4b42/1546842769795.png)

*图 1：试图根据气压表读数序列预测每日降雨量的简单机器学习模型可能考虑的不确定性。偶然事件不确定性（Aleatoric Uncertainty）源自数据收集过程，是不可降低的随机性。认知不确定性（Epistemic  Uncertainty）反映的是模型做出正确预测的置信程度。最后，超出分布的误差（Out-of-Distribution  error）是指当模型的输入不同于其训练数据时出现的不确定性（比如太阳温度等其它异常现象）。*

#### 偶然事件不确定性

偶然事件不确定性得名于拉丁语词根 aleatorius，意为「将几率纳入创造过程」。这描述的是源自数据生成过程本身的随机性；不能简单地通过收集更多数据而消除的噪声。就像你不能预知结果的抛硬币。

偶然事件不确定性会从输入传播到模型的预测结果。

偶然事件不确定性会从输入传播到模型的预测结果。假设有一个简单模型 $y=5x$，它的输入取自正态分布  $x∼N(0,1)$。在这一案例中，$y∼N(0,5)$，因此该预测分布的偶然事件不确定性可描述为 $σ=5$。当然，当输入数据 x 的随机结构未知时，预测结果的偶然事件不确定性将更难估计。

也许有人会想：因为偶然事件不确定性是不可约减的，所以我们对此无能无力，直接忽略它就好了。这可不行！在训练模型时，应该注意选择能够正确地代表偶然事件不确定性的输出表征。**标准的 LSTM 不会得出概率分布，所以学习抛硬币的结果时只会收敛成均值。**相对而言，用于语言生成的模型能够得出一系列类别分布（词或字符），这能**纳入句子完成任务中的固有歧义性。**

#### 认知不确定性

> 「好的模型都是相似的；差的模型各有不同。」

认知不确定性来自希腊语词根 epistēmē，属于与知识相关的知识。这衡量了我们对「源自我们对正确模型参数的无知程度」的正确预测的无知程度。

下图展示了一个在某个简单的一维数据集上的[高斯过程](https://mp.weixin.qq.com/cgi-bin/appmsg?t=media/appmsg_edit&action=edit&type=10&appmsgid=503271542&isMul=1&token=398966350&lang=zh_CN)回归模型。其置信区间反映了认知不确定性；训练数据的认知不确定性为零（红点）。随着我们离训练数据点的距离越远，模型应该给预测分布分配越高的标准差。不同于偶然事件不确定性，认知不确定性可以通过收集更多数据和「去除」模型缺乏知识的输入区域而降低。

![](https://image.jiqizhixin.com/uploads/editor/2e2ce64f-0a68-4343-b6a3-c042b6b45093/1546842769896.png)

*图 2：一维高斯过程回归模型，展现了训练集之外的输入上的认知不确定性*

深度学习与高斯过程之间有丰富的关联。人们希望能通过神经网络的表征能力扩展高斯过程的能感知不确定性的性质。不幸的是，高斯过程难以扩展用于大数据集的统一随机小批量设置，而且研究大型模型和数据集的人也已经不再支持这种方法。

**如果人们希望在选择模型族时有最大的灵活度，使用集成（ensemble）方法来估计不确定性是一个好选择，这实际上就是使用「多个独立的学习后的模型」。**高斯过程模型是分析式地定义预测分布，而集成方法则被用于计算预测的经验分布（empirical distribution）。

由于训练过程中出现的随机化偏差，任何单个模型都会有一些误差。在集成方法中，其它模型往往会揭示出单个模型特有的错处之处，同时认同推理正确的预测结果；因此**集成模型是很强大的**。

我们该如何随机取样模型以构建一个集成模型呢？在使用 bootstrap aggregation 构建集成模型时，我们首先从一个大小为 N  的训练数据集开始，并从原始训练集采样 M 个大小为 N 的数据（有替换，这样每个数据集都不会占据整个数据集）。分别在这些数据集上训练 M 个模型，再将它们的预测结果综合起来得到一个经验预测分布。

如果训练多个模型的成本过高，也可以使用 [dropout](https://mp.weixin.qq.com/cgi-bin/appmsg?t=media/appmsg_edit&action=edit&type=10&appmsgid=503271542&isMul=1&token=398966350&lang=zh_CN) 训练来近似模型集成。**但是，引入 dropout 会涉及到一个额外的超参数并且也可能有损单个模型的表现（对于实际应用而言往往是不可接受的；在实际应用中，校准不确定性估计相对准确度而言是次要的）。**

因此，如果能使用大量计算资源（就像谷歌那样），通常只需要重复训练多个模型副本，这要更加容易。这还能在无损性能的前提下享受集成方法的好处。这篇[深度集成论文](https://arxiv.org/pdf/1612.01474.pdf)就采用了这一方法。这篇论文的作者还提到由不同的权重初始化带来的随机训练动态足以得到一个多样化的模型集合，而不必通过 bootstrap aggregation 来降低训练集多样性。从实际的工程开发角度看，押注不会影响模型性能的风险估计方法或研究者想要尝试的其它方法是明智的。

#### 超出分布的不确定性

对于我们的降雨量预测器，如果我们为其提供的输入不是气压表读数序列，而是太阳的温度呢？要是提供一个全是零的序列呢？或者用不同的单位记录的气压表读数呢？RNN 还是会继续计算，为我们提供一个预测，但结果很可能毫无意义。

这个模型完全没有能力基于通过不同于训练集创建流程的流程生成的数据进行预测。在基准驱动的机器学习研究领域，这是一种常被忽视的失败模式，因为我们通常假设训练、验证和测试集都完全由独立同分布的数据构成。

确定输入是否「有效」是实际部署机器学习所面临的一个严峻问题，这也被称为超出分布（OoD/Out of Distribution）问题。OoD 与「模型误设错误」和「异常检测」是同义词。

异常检测不仅对增强机器学习系统稳健性很重要，而且本身也是一种非常有用的技术。举个例子，我们可能想构建一个能监控健康人士的生命体征的系统，让该系统能在指标异常时发出警报，这并不需要系统之前见过这种异常的病理模式。我们也可以用异常检测来管理数据中心的「健康」，一旦有不同寻常的事情发生（磁盘满载、安全漏洞、硬件故障等），我们就能得到通知。

因为 OoD 输入仅出现在测试时间，所以我们不应假设我们事先知道模型会遇到的异常的分布。这正是 OoD 检测的棘手之处——我们必须针对模型在训练阶段从未见过的输入来增强该模型对这些输入的抗性！这正是对抗式机器学习中描述的标准的攻击场景。

机器学习模型有两种处理 OoD 输入的方法：1）在输入到达模型前就识别出糟糕的输入；2）根据模型预测结果的「怪异性」来帮助我们鉴别可能存在问题的输入。

在第一种方法中，我们不会对下游机器学习任务做任何假设，只会考虑输入是否处于训练分布中的问题。这正是生成对抗网络（GAN）中判别器的工作。但是，单个判别器并不具有完美的稳健性，因为它只擅长辨别真实数据分布和生成器得到的分布；对于不属于其中任意一个分布的输入而言，它有可能得出任意的预测结果。

除了判别器，我们也可以构建一个分布内数据的密度模型，比如一个核密度估计器或用一个 Normalizing Flow 来拟合数据。Hyunsun Choi 和我最近研究过这一问题，参阅我们最近使用现代生成模型执行 OoD 检测的论文：https://arxiv.org/abs/1810.01392

第二种 OoD 检测方法涉及到使用任务模型的预测（认知）不确定性来辨别哪些输入是  OoD。理想情况下，模型在收到错误的输入时应该会得到「怪异的」的预测分布 p(y|x)。举个例子，Hendrycks and  Gimpel（https://arxiv.org/abs/1610.02136）表明 OoD 输入的最大化 softmax  概率（预测得到的类别）往往低于分布内的输入。这里，不确定性反比于最大 softmax 概率建模的「置信度」。高斯过程这样的模型能通过构造为我们提供这些不确定性估计，或者我们也可通过深度集成来计算认知不确定性。

在强化学习领域，人们实际上假设 OoD 输入是一件好事，因为这是智能体还不知道如何处理的世界输入。鼓励策略寻找自己的 OoD  输入能实现「内在的好奇心」，从而探索模型的预测效果较差的区域。这是很好的做法，但我很好奇如果将这种好奇心驱动的智能体部署到现实世界（其中传感器很容易损坏，也会发生其它实验异常）中会怎样。机器人如何区分「未曾见过的状态」（好）和「传感器损坏情况」（坏）？这能得到能学习与它们的传感机制交互从而生成最大化新颖度的智能体吗？

#### 谁来看住看门狗？

正如前一节提到的那样，保护自己免受 OoD 输入影响的一种方法是设置一个能够「像看门狗一样」监控模型输入的似然模型（likelihood  model）。我更喜欢这种方法，因为这能将 OoD 输入问题与任务模型中的认知和偶然事件不确定性隔开。从工程开发角度看，这能让分析工作更轻松。

但我们不应该忘记这个似然模型也是一个函数近似器，可能存在自己的 OoD 错误！我们近期的生成式集成方法（Generative Ensembles，https://arxiv.org/abs/1810.01392，也可参阅 DeepMind 的同期研究 https://arxiv.org/abs/1810.09136）研究表明，在使用一个 CIFAR 似然模型时，来自 SVHN 的自然图像实际上比 CIFAR 分布内的图像本身还有更高的可能性！

![](https://image.jiqizhixin.com/uploads/editor/b4f5afca-02a3-4e72-b032-1fdfb2c614e2/1546842770030.png)

*图 3：似然估计涉及到一个本身也可能易受 OoD 输入影响的函数近似器。比起 CIFAR 测试图像，CIFAR 的似然模型会给 SVHN 图像分配更高的概率！*

但是，希望还是有的！研究表明，似然模型的认知不确定性对该似然模型自身而言是出色的 OoD 检测器。通过将认知不确定性估计与密度估计结合起来，我们能以一种与模型无关的方式使用似然模型的集成来保护机器学习模型免受 OoD 输入影响。

#### 校准：下一件大事？

警告：只是因为一个模型能够确定一个预测结果的置信区间，并不意味着该置信区间能真正反映结果在现实中的实际概率！

[置信区间](https://mp.weixin.qq.com/cgi-bin/appmsg?t=media/appmsg_edit&action=edit&type=10&appmsgid=503271542&isMul=1&token=398966350&lang=zh_CN)（比如 2σ）隐式地假设预测分布是高斯分布，但如果你想要预测的分布是多模态分布或重尾分布，那么你的模型将不会得到很好的校准！

假设我们的降雨量预测 RNN 告诉我们今日的降雨将为 N(4,1) 英寸，如果我们的模型经过校准，那么如果我们一次又一次地在同样的条件下重复这个实验（也许每一次都重新训练该模型），那么我们实际将会观察到实际的降雨量分布正是 N(4,1)。

当今学术界开发的机器学习模型大都是针对测试准确度或某个拟合度函数优化的。研究者执行模型选择的方式不是通过重复相同的实验来部署模型，再衡量校准误差，所以不出意外，我们的模型往往只有很差的校准，参阅：https://arxiv.org/abs/1706.04599

展望未来，如果我们要信任部署在现实世界中的机器学习系统（机器人、医疗系统等），**我认为「证明我们的模型能够正确理解世界」的一种远远更为强大方法是针对统计校准测试它们**。优良的校准也意味着优良的准确度，所以这是一个更严格的更高的优化指标。

#### 不确定性应该是标量吗？

尽管标量的不确定性很有用，但它们的信息量永远不及它们所描述的随机变量，我发现粒子滤波和分布式强化学习等方法非常酷，因为它们是在整个分布上运行的算法，让我们无需借助简单的正态分布来跟踪不确定性。除了使用单标量的「不确定性」来塑造基于机器学习的决策，现在我们也可以在决定要做什么时查询分布的整体结构。

Dabney et al. 的 Implicit Quantile Networks  论文（https://arxiv.org/pdf/1806.06923.pdf）很好地讨论了如何基于回报的分布构建「风险敏感型智能体」。在某些环境中，人们可能更偏好倾向于探索未知的机会主义策略；而在另一些环境中，未知事物可能并不安全，应当避开。风险度量的选择本质上决定了如何将回报的分布映射成一个标量数量，然后再根据这个量进行优化。所有的风险度量都可以根据分布计算得到，所以预测整个分布能让我们将多个风险定义轻松地组合起来。此外，支持灵活的预测分布似乎也是一个提升模型校准的好方法。

![](https://image.jiqizhixin.com/uploads/editor/d9067a56-9127-4289-9fa9-c57e9aba171f/1546842770192.png)

*图 4：多种风险度量在 Atari 游戏上的表现，来自这篇 IQN 论文：https://arxiv.org/abs/1806.06923*

对金融资产管理者而言，风险度量是一个非常重要的研究主题。简单纯粹的马科维茨（Markowitz）投资组合的目标是最小化投资组合回报  的一个加权的方差。但是，方差是「风险」在金融语境的一个不直观的选择：大多数投资者根本不在乎回报超出预期，而只是希望最小化回报少或亏损的可能性。由于这个原因，Value-at-Risk、Shortfall Probability 和 Target Semivariance 等仅关注「糟糕」结果的概率的风险度量是更有用的优化目标。

不幸的是，它们也更难分析。我希望在分布式强化学习、蒙特卡洛方法和灵活的生成模型上的研究能让我们构建起能与投资组合优化器很好地协同工作的风险度量的可微分弛豫（differentiable relaxations）。如果你在金融行业工作，我强烈建议你阅读 IQN 论文中的「强化学习中的风险」一节。

深度学习模型给出的预测结果并不总是可靠的。在无人驾驶等安全性要求较高的领域中，完全依赖深度模型进行决策有可能导致灾难性的后果（药物发现的实验代价较高）。如果能够让深度学习模型对于错误的预测给出一个较高的不确定性，我们就能判断一个预测结果可信程度。因此，我们需要对不确定性进行建模。

衡量不确定性最直观的方法就是方差。

一个单独输出值是得不到方差的。如果说我们能够用同一个模型，对同一个样本进行 T 次预测，而且这T次的预测值各不相同，就能够计算方差。问题是同一个模型同一个样本，怎么得到不同的输出呢？概率学家就说了，我们让学到的模型参数 $q_\theta$ 不是确定的值，而是一个分布，那么就可以从这个分布中采样，每一次采样，得到的weight都是不同的，这样结果也是不同的，目的就达到了。但是，怎么学习这样的分布呢？概率学家又说了，有现成的呀，dropout 就是。使用了 dropout 来训练 DNN 时，模型的参数可以看成是服从一个伯努利分布。在预测的时候，仍然将 dropout 打开，预测 T 次，均值就是最终的预测值，而方差就是不确定度。这样就得到深度学习的不确定度了。这种方法也被称为 MC Dropout 贝叶斯神经网络。

但是，不确定性有两种。一种称之为偶然不确定性（Aleatoric  Uncertainty），是由于观测数据中的固有噪声导致的。这种不确定性是无法被消除的。另外一种称之为感知不确定性（Epistemic  Uncertainty），与模型相关，是由于训练不完全导致的。如果给它更多的训练数据来弥补现有模型知识上的不足，这种不确定性从理论上来说是可以消除的。MC Dropout 只能得到关于模型的感知不确定性，而不能捕获数据的偶然不确定性，这是有问题的。这就是本文要解决的问题了。

## 贝叶斯神经网络

假定模型参数服从一个高斯先验分布： ![[公式]](https://www.zhihu.com/equation?tex=W+%5Csim+%5Cmathcal%7BN%7D+%280%2C+I%29) 。给定观测数据集

![[公式]](https://www.zhihu.com/equation?tex=X%3D%5C%7Bx_1%2C+%5Ccdots%2C+x_n%5C%7D%2C+Y%3D%5C%7By_1%2C+%5Ccdots%2Cy_n%5C%7D) 时，可以使用贝叶斯推断来计算模型参数的后验分布 ![[公式]](https://www.zhihu.com/equation?tex=p%28W%7CX%2CY%29) 。对于回归任务，通常假定似然是一个高斯分布：![[公式]](https://www.zhihu.com/equation?tex=p%28W%7CX%2CY%29%3D%5Cmathcal%7BN%7D%28f%5EW%28x%29%2C%5Csigma%5E2%29) 。其中， ![[公式]](https://www.zhihu.com/equation?tex=f%5EW) 为模型的输出， ![[公式]](https://www.zhihu.com/equation?tex=%5Csigma) 为噪声项。而对于分类任务，则经常对输出进行归一化，用 softmax 对其进行压缩处理： ![[公式]](https://www.zhihu.com/equation?tex=p%28W%7CX%2CY%29%3D%5Ctext%7BSoftmax%7D%28f%5EW%28x%29%29) 。

贝叶斯神经网络虽然很好定义，但是实际操作起来比较困难。主要原因在于边际分布 ![[公式]](https://www.zhihu.com/equation?tex=p%28Y%7CX%29) 没法算。而这一项又是贝叶斯推断所必需的。因此只能通过近似的方法来逼近真实的参数分布。

> 贝叶斯推断公式：
> ![[公式]](https://www.zhihu.com/equation?tex=p%28W%7C+X%2C+Y%29%3D%5Cfrac%7Bp%28Y+%7C+X%2C+W%29+p%28W%29%7D%7B+p%28Y+%7C+X%29+%7D%5C%5C)

Dropout 变分推断是一种常用的近似方法。这种方法在除了在训练时要使用 dropout 之外，在预测时，也要将 dropout 打开，执行 T 次预测取其平均值。**理论证明这种方法等价于在最小化 KL 散度**。

利用 Dropout 进行训练时，其最小化目标为

![](https://www.zhihu.com/equation?tex=%5Cmathcal%7BL%7D%28%5Ctheta%2C+p%29%3D-%5Cfrac%7B1%7D%7BN%7D+%5Csum_%7Bi%3D1%7D%5E%7BN%7D+%5Clog+p%28%5Cmathrm%7By%7D_i%7Cf%5E%7B%5Cwidehat%7BW%7D_i%7D+%28%5Cmathrm%7Bx%7D_i%29%29+%2B+%5Cfrac%7B1-p%7D%7B2N%7D+%5C%7C+%5Ctheta%5C%7C%5E2+%5C%5C)

其中，第一项为负对数似然，第二项为正则化参数。 ![[公式]](https://www.zhihu.com/equation?tex=p) 为dropout中的随机失活率。 ![[公式]](https://www.zhihu.com/equation?tex=%5Cwidehat%7BW%7D_i+%5Csim+q_%7B%5Ctheta%7D%5E%2A+%28W%29) 。![[公式]](https://www.zhihu.com/equation?tex=N) 为数据点个数。

在回归任务中，通常假设似然是一个高斯分布，那么负对数似然可以写为如下形式：

![](https://www.zhihu.com/equation?tex=-%5Clog+p%28%5Cmathrm%7By%7D_i+%7C+f%5E%7B%5Cwidehat%7BW%7D_i%7D%28%5Cmathrm%7Bx%7D_i%29%29+%5Cvarpropto++%5Cfrac%7B1%7D%7B2+%5Csigma%5E2%7D+%5C%7C+%5Cmathrm%7By%7D_i+-+f%5E%7B%5Cwidehat%7BW%7D_i%7D%28%5Cmathrm%7Bx%7D_i%29%5C%7C%5E2+%2B+%5Cfrac%7B1%7D%7B2%7D+%5Clog+%5Csigma%5E2+%5C%5C)

![[公式]](https://www.zhihu.com/equation?tex=%5Csigma) 表示模型输出值的噪声，一定意义上衡量了输出的不确定程度。

### 感知不确定性

感知不确定性是关于模型参数的。

为了捕获这个不确定性，我们可以从模型参数的分布中采样多次，得到 ![[公式]](https://www.zhihu.com/equation?tex=T) 个模型，用这 ![[公式]](https://www.zhihu.com/equation?tex=T) 个模型对同一个样本做预测，看看 ![[公式]](https://www.zhihu.com/equation?tex=T) 次的预测结果有多么的不稳定。

对于分类问题， ![[公式]](https://www.zhihu.com/equation?tex=T) 次预测的概率为：

![](https://www.zhihu.com/equation?tex=p%28y%3Dc%7C%5Cmathrm%7Bx%7D%2CX%2CY%29+%5Capprox+%5Cfrac%7B1%7D%7BT%7D+%5Csum_%7Bt%3D1%7D%5E%7BT%7D+%5Ctext%7BSoftmax%7D+%28f%5E%7B%5Cwidehat%7BW%7D_t%7D%28%5Cmathrm%7Bx%7D%29%29+%5C%5C)

其中， ![[公式]](https://www.zhihu.com/equation?tex=%5Cwidehat%7BW%7D_t+%5Csim+q_%7B%5Ctheta%7D%5E%2A+%28W%29) 。不确定性可以用熵来衡量： ![[公式]](https://www.zhihu.com/equation?tex=H%28%5Cmathrm%7Bp%7D%29%3D-+%5Csum_%7Bc%3D1%7D%5EC+p_c+%5Clog+p_c) 。

对于回归问题，不确定性可以用输出值的方差来表示： ![[公式]](https://www.zhihu.com/equation?tex=%5Cfrac%7B1%7D%7BT%7D+%5Csum_%7Bt%3D1%7D%5ET+%5Cleft%28+f%5E%7B%5Cwidehat%7BW%7D_t%7D+%28%5Cmathrm%7Bx%7D%29+-+E%28%5Cmathrm%7By%7D%29+%5Cright%29%5E2++%5C%5C) 其中， ![[公式]](https://www.zhihu.com/equation?tex=E%28%5Cmathrm%7By%7D%29+%5Capprox+%5Cfrac%7B1%7D%7BT%7D+%5Csum_%7Bt%3D1%7D%5E%7BT%7D+f%5E%7B%5Cwidehat%7BW%7D_t%7D%28%5Cmathrm%7Bx%7D%29) 表示输出的均值。

### 偶然不确定性

偶然不确定性衡量的是数据本身存在的噪声，某种程度上衡量了一个 instance 的预测难度，因此可以将它看作是 instance 的一个函数：对于预测结果比较离谱的 instance，这个函数值应该比较大；而对于容易预测的 instance，相应的函数值应该较小。可以用以下的损失函数来对其进行建模，![[公式]](https://www.zhihu.com/equation?tex=L%28%5Ctheta%29+%3D+%5Cfrac%7B1%7D%7BN%7D+%5Csum_%7Bi%3D1%7D%5E%7BN%7D+%5Cfrac%7B1%7D%7B2%5Csigma%7B%28%5Cmathrm%7Bx%7D_i%29%5E2%7D%7D+%5C%7C+%5Cmathrm%7By%7D_i+-+f%28%5Cmathrm%7Bx%7D_i%29%5C%7C%5E2+%2B+%5Cfrac%7B1%7D%7B2%7D+%5Clog+%5Csigma%28%5Cmathrm%7Bx%7D_i%29%5E2+%5C%5C)

![[公式]](https://www.zhihu.com/equation?tex=%5Csigma%28%5Cmathrm%7Bx%7D_i%29) 即表示 ![[公式]](https://www.zhihu.com/equation?tex=%5Cmathrm%7Bx%7D_i) 偶然不确定性。这里没有对模型参数执行变分推断，而是用了 MAP，只能得到一组单一的模型参数值而不是一个分布，因而也无法捕获模型参数的感知不确定性。由此而实现了两种不确定性的分离。

简单来说，感知不确定性是用多次预测结果的方差来决定的，在多次预测中，所用的模型参数都是不一样的，因此这种做法捕获了模型参数的感知不确定性。而偶然不确定性是由样本的特征决定的，和模型参数是无关的。

## 将两种不确定性结合

### 回归任务

为了将两种不确定性结合到同一个模型中，我们需要两组输出：一组是最终的预测结果 ![[公式]](https://www.zhihu.com/equation?tex=%5Chat%7B%5Cmathrm%7By%7D%7D) ，另一组是样本的偶然不确定性 ![[公式]](https://www.zhihu.com/equation?tex=%5Chat%7B%5Csigma%7D%5E2) 。即

![[公式]](https://www.zhihu.com/equation?tex=%5B%5Chat%7B%5Cmathrm%7By%7D%7D%2C+%5Chat%7B%5Csigma%7D%5E2%5D+%3D+f%5E%7B%5Cwidehat%7BW%7D%7D+%28%5Cmathrm%7Bx%7D%29+%5C%5C)

通过最小化以下的损失函数来训练模型：

![[公式]](https://www.zhihu.com/equation?tex=%5Cmathcal%7BL%7D_%7BB+N+N%7D%28%5Ctheta%29%3D%5Cfrac%7B1%7D%7BD%7D+%5Csum_%7Bi%7D+%5Cfrac%7B1%7D%7B2%7D+%5Chat%7B%5Csigma%7D_%7Bi%7D%5E%7B-2%7D%5Cleft%5C%7C%5Cmathbf%7By%7D_%7Bi%7D-%5Chat%7B%5Cmathbf%7By%7D%7D_%7Bi%7D%5Cright%5C%7C%5E%7B2%7D%2B%5Cfrac%7B1%7D%7B2%7D+%5Clog+%5Chat%7B%5Csigma%7D_%7Bi%7D%5E%7B2%7D+%5C%5C) 

在论文中的深度回归任务中， ![[公式]](https://www.zhihu.com/equation?tex=D) 表示图片 ![[公式]](https://www.zhihu.com/equation?tex=%5Cmathrm%7Bx%7D) 中的像素点数量， ![[公式]](https://www.zhihu.com/equation?tex=i) 为像素的索引。上面的损失包含了两部分：一部分是回归模型的残差，用于捕获模型参数的感知不确定性；另一部分是像素点的偶然不确定性，充当正则化项。注意到，在学习偶然不确定性时，其实是不需要标记的。如果一个像素 ![[公式]](https://www.zhihu.com/equation?tex=i) 很难预测对，为了最小化整个损失， ![[公式]](https://www.zhihu.com/equation?tex=%5Chat%7B%5Csigma%7D_i) 会相应地变大，而 ![[公式]](https://www.zhihu.com/equation?tex=%5Cfrac%7B1%7D%7B2%7D+%5Clog+%5Chat%7B%5Csigma%7D_i%5E2) 又会防止 ![[公式]](https://www.zhihu.com/equation?tex=%5Chat%7B%5Csigma%7D_i) 变得无穷大。并不需要 ![[公式]](https://www.zhihu.com/equation?tex=%5Csigma_i) 的 ground truth。

实际训练中， ![[公式]](https://www.zhihu.com/equation?tex=%5Chat%7B%5Csigma%7D_i%5E%7B-2%7D) 其实相当于一项自适应的权重，对于难以预测的样本，数据中存在较多的固有噪声，这项权重比较小；而对于容易预测的样本，数据中存在的固有噪声比较少，这项权重会比较大。这会让模型在训练过程中区别地对待不同的样本。

### 分类任务

在分类任务中，对于一个像素 ![[公式]](https://www.zhihu.com/equation?tex=i) ，模型会输出一个预测向量 ![[公式]](https://www.zhihu.com/equation?tex=%5Cmathrm%7Bf%7D_i) ，然后再通过 softmax 操作得到一组概率 ![[公式]](https://www.zhihu.com/equation?tex=%5Cmathrm%7Bp%7D_i)。假定预测向量服从一个高斯分布：

![[公式]](https://www.zhihu.com/equation?tex=%5Chat%7B%5Cmathrm%7Bx%7D%7D_i%7CW+%5Csim+%5Cmathcal%7BN%7D+%28%5Cmathrm%7Bf%7D_i%5EW%2C%28%5Csigma_i%5EW%29%5E2%29+%5C%5C+%5Chat%7B%5Cmathrm%7Bp%7D%7D_i+%3D+%5Ctext%7BSoftmax%7D+%28%5Chat%7B%5Cmathrm%7Bx%7D%7D_i%29)

 这里 ![[公式]](https://www.zhihu.com/equation?tex=%5Cmathrm%7Bf%7D_i%5EW) 和 ![[公式]](https://www.zhihu.com/equation?tex=%5Csigma_i%5EW) 是网络参数为 ![[公式]](https://www.zhihu.com/equation?tex=W) 时的输出。相当于对向量 ![[公式]](https://www.zhihu.com/equation?tex=%5Cmathrm%7Bf%7D_i%5EW) 施加了一个方差为 ![[公式]](https://www.zhihu.com/equation?tex=%5Csigma_i%5EW)的噪声。

训练模型的损失函数可以写为：

![[公式]](https://www.zhihu.com/equation?tex=%5Cbegin%7Baligned%7D+%5Chat%7B%5Cmathbf%7Bx%7D%7D_%7Bi%2C+t%7D+%26%3D%5Cmathrm%7Bf%7D_%7Bi%7D%5E%7B%5Cmathrm%7BW%7D%7D%2B%5Csigma_%7Bi%7D%5E%7B%5Cmathrm%7BW%7D%7D+%5Cepsilon_%7Bt%7D%2C+%5Cquad+%5Cepsilon_%7Bt%7D+%5Csim+%5Cmathcal%7BN%7D%280%2C+I%29+%5C%5C+%5Cmathcal%7BL%7D_%7Bx%7D+%26%3D%5Csum_%7Bi%7D+%5Clog+%5Cfrac%7B1%7D%7BT%7D+%5Csum_%7Bt%7D+%5Cexp+%5Cleft%28%5Chat%7Bx%7D_%7Bi%2C+t%2C+c%7D-%5Clog+%5Csum_%7Bc%5E%7B%5Cprime%7D%7D+%5Cexp+%5Chat%7Bx%7D_%7Bi%2C+t%2C+c%5E%7B%5Cprime%7D%7D%5Cright%29+%5Cend%7Baligned%7D+%5C%5C+%5Ctag%7B1%7D) 

第二项实则为交叉熵损失函数化简后的结果。

> 交叉熵损失的简单推导：
> 假定一共有C个类别，像素 ![[公式]](https://www.zhihu.com/equation?tex=i) 属于类别 ![[公式]](https://www.zhihu.com/equation?tex=c) ， ![[公式]](https://www.zhihu.com/equation?tex=y_%7Bi%2Cc%27%7D+%5Cin+%5C%7B0%2C1%5C%7D) ，那么像素 ![[公式]](https://www.zhihu.com/equation?tex=i) 交叉熵损失为
> ![[公式]](https://www.zhihu.com/equation?tex=%5Csum_%7Bc%27%3D1%7D%5E%7BC%7D+y_%7Bi%2Cc%27%7D+%5Clog+p_%7Bi%2Cc%27%7D+%3D+y_%7Bi%2Cc%7D+%5Clog+p_%7Bi%2Cc%7D+%5C%5C+%3D+%5Clog+%5Cfrac%7B%5Cexp%28%5Chat%7B%5Cmathrm%7Bx%7D%7D_%7Bi%2Cc%7D%29%7D%7B+%5Csum_%7Bc%27%7D+%5Cexp+%28%5Chat%7B%5Cmathrm%7Bx%7D%7D_%7Bi%2Cc%27%7D%29%7D+%3D+%5Chat%7B%5Cmathrm%7Bx%7D%7D_%7Bi%2Cc%7D+-+%5Clog+%5Csum_%7Bc%27%7D+%5Cexp+%28%5Chat%7B%5Cmathrm%7Bx%7D%7D_%7Bi%2Cc%27%7D%29+%5C%5C) 
> 因为要执行T次预测，因此损失也要取T次的平均，由此得到了公式 (1)。



简单来说，贝叶斯神经网络或者 MC Dropout 能够捕获感知不确定性，额外添加的 ![[公式]](https://www.zhihu.com/equation?tex=%5Csigma) 则用来捕获偶然不确定性。

## 总结

- Monte Carlo dropout 是一种易于实现的近似贝叶斯不确定性的技术，但对于该近似是否确实准确仍存在一些分歧。实际上，我发现 Monte Carlo dropout 对简单模型有效，但对于复杂模型的方法在精度和性能上都存在一些问题。

- 不确定性/风险度量是「随机性」的标量度量。为了优化和数学计算的方便，将随机变量浓缩成了单个数值。
- 预测不确定性可以分解成偶然事件不确定性（来自数据收集过程的不可约减的噪声）、认知不确定性（对真实模型的无知）和超出分布的不确定性（在测试时，输入存在问题）。
- 认知不确定性可以通过 softmax 预测阈值设置或集成方法降低。
- 我们可以不将 OoD 不确定性传播到预测中，而是使用一种与任务无关的过滤机制来滤除「有问题的输入」。
- 密度模型是在测试时过滤输入的一个好选择。但是，需要认识到，密度模型只是真实密度函数的近似，本身也可能易受分布之外的输入的影响。
- 自我插拔：生成式集成方法能降低似然模型的认知不确定性，所以它们可被用于检测 OoD 输入。
- 校准很重要，而且在研究模型中被低估了。
- 某些算法（分布式强化学习）能将机器学习算法延展成能产出灵活分布的模型，这能比单个风险度量提供更多的信息。

## Links

- [深度学习中的不确定性](https://zhuanlan.zhihu.com/p/98756147)
- [如何创造可信任的机器学习模型？先要理解不确定性](https://www.jiqizhixin.com/articles/2019-01-07-6)