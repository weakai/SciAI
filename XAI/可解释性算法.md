---
title: 可解释性算法
date: 2022-08-5
tags: [可解释性算法]
---

## 局部与全局



LIME：一种和模型无关的局部可解析性算法。

Scaliency Maps: 基于反向传播梯度生成heatmap，显示输入像素对于输出的影响。

LRP: 基于反向传播 relevance score 生成 heatmap。(主要用于图像领域，目前有不少 nlp 方向的应用)

DeepLIFT: 一种改进的基于反向传播梯度生成 heatmap 的算法。

SHAP: 基于博弈论 shapely 值计算特征的重要度。（现成的 python 包，实际应用会遇到不少坑）

机器学习的可解释性，包括两个方面：一是局部可解释性，二是全局可解释性。

## 算法

### 基于扰动的正向传播方法

原理：对单个输入或神经元产生干扰，并观察对神经网络中后续神经元的影响。

最早的此类方法由Zeiler&Fergus在2013年提出，他们用滑动窗口遮挡图像的不同部分，并观察输出的变化。LIME也属于这一类，它使用从输入扰动中收集的数据建立线性模型来近似网络的局部行为。

缺陷：
- 由于每次扰动都需要通过网络进行单独的正向传播，因此这些方法在计算上效率低下。
- 饱和问题: 可能低估满足输出贡献的特征的重要性。

### 基于反向传播的方法

原理：将重要信号从输出神经元通过各层反向传播到输入神经元，使之高效。

从本质上说，反卷积和导向反向传播的基础都是反向传播，其实说白了就是对输入进行求导，以上三者唯一的区别在于反向传播过程中经过ReLU层时对梯度的不同处理策略。
缺陷：由于负梯度归零，所以反卷积和导向反向传播并不能突出显示对输出有负面贡献的输入；另外，以上三种方法都不能解决饱和及阈值伪影问题（梯度的不连续性会导致不需要的伪影）。

#### Gradients

Simonyan 等人最先提出了利用反向传播推断特征重要性的解释方法(Grad)，具体地，Grad方法通过利用反向传播算法计算模型的输出相对于输入图片的梯度来求解该输入图片所对应的分类显著图(Saliency Map)。如下图，亮度越高的区域代表这个Pixel对于预测结果的影响越大。

#### Deconvolutional Networks

Zeiler 等人提出了反卷积网络(DeconvNet)，通过将 DNN 的高层激活反向传播到模型的输入以识别输入图片中负责激活的重要部分。

#### Guided Backpropagation

Springenberg 等人将 Grad 方法与反卷积网络相结合提出了导向反向传播方法(GuidedBP)，通过在反向传播过程中丢弃负值来修改 ReLU 函数的梯度。

#### LRP

Bach 等人提出了一种分层相关性传播方法(LRP)，用于计算单个像素对图像分类器预测结果的贡献，LRP 的核心是利用反向传播将高层的相关性分值递归地传播到低层直至传播到输入层。Shrikumar和Kindermans的研究表明，在不修改数值稳定性的情况下，原始LRP规则在比例因子内等价于显著性图和输入之间的元素积，也就是梯度×输入。

缺陷：梯度×输入通常会比单独使用梯度效果更好，因为它会利用输入的符号和强度，但仍无法解决饱和及阈值伪影问题。

#### Integrated Gradients

与只计算输出针对当前输入的梯度不同， Sundararajan 等人提出了一种集成梯度方法(Integrated)，该方法通过计算输入从某些起始值按比例放大到当前值的梯度的积分代替单一梯度，有效地解决了 DNN 中神经元饱和问题导致无法利用梯度信息反映特征重要性的问题。 

缺陷：从数值上获得高质量的积分会增加计算开销；此外，这种方法仍会产生误导性的结果。

### Grad-CAM and Guided CAM

### DeepLIFT

## Reference

- []()