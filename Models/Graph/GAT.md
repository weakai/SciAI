---
title: GAT
date: 2022-7-18
---

GAT 相对于之前提出的方法的优点在于

- 与 GCN 结构是类似，采用了局部网络的方式
  - 训练GAT模型的时候我们不再需要去了解整个图结构的类型，图的构成样子了，我们仅仅需要去知道每个节点的邻节点即可。
- GAT 使用 self-attention 方式为每个节点的周围邻居节点分配权重，也就是说，GAT 的节点更新方式的具体实例如图所示。
  - 从理论和实验中的结果都表明，这种 attention 分配权重的方式帮助了 GAT 能够有更好结果。
  - 通过 attention 的计算，GAT 在计算新的节点表示时引入了一个权值矩阵，不再是一个 0,1 邻接矩阵。
