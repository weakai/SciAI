---
title: GCN
---

## 图网络的分类

![](https://cdn.jsdelivr.net/gh/xxzhai123/img/imgv2-1767c06f11e8afc95e13d99f36f7ea88_720w.jpg)

### Graph Embedding

图嵌入（Graph Embedding/Network Embedding，GE），属于表示学习的范畴，也可以叫做网络嵌入，图表示学习，网络表示学习等等。通常有两个层次的含义：

- **将图中的节点表示成低维、实值、稠密的向量形式**，使得得到的向量形式可以在向量空间中具有表示以及推理的能力，这样的向量可以用于下游的具体任务中。例如用户社交网络得到节点表示就是每个用户的表示向量，再用于节点分类等；

- **将整个图表示成低维、实值、稠密的向量形式**，用来对整个图结构进行分类；

图嵌入的方式主要有三种：

- 矩阵分解
- Deepwalk
- Graph Neural Network

### Graph Neural Network

图神经网络(Graph Neural Network, GNN)是指神经网络在图上应用的模型的统称，根据采用的技术不同和分类方法的不同，又可以分为下图中的不同种类，例如从传播的方式来看，图神经网络可以分为图卷积神经网络（GCN），图注意力网络（GAT，缩写为了跟GAN区分），Graph LSTM 等等，本质上还是把文本图像的那一套网络结构技巧借鉴过来做了新的尝试。但在这篇文章中并不会细细介绍下面的每一种，作为入门篇，我们着重理解最经典和最有意义的基础模型GCN，这也是理解其他模型的基础。

### Graph Convolutional Network

图卷积神经网络(Graph Convolutional Network, GCN)正如上面被分类的一样，是一类采用图卷积的神经网络，发展到现在已经有基于最简单的图卷积改进的无数版本，在图网络领域的地位正如同卷积操作在图像处理里的地位。

## Preface

GCN 是一种卷积神经网络，它可以直接在图上工作，并利用图的结构信息。

GCNs 用于图上的半监督学习

它解决的是对图（如引文网络）中的节点（如文档）进行分类的问题，其中仅有一小部分节点有标签（半监督学习）。

![半监督学习](https://static.leiphone.com/uploads/new/sns/article/202009/1599636329616208.png)

在 Graphs 上进行半监督学习的例子。有些节点没有标签（未知节点）

目前，大多数图神经网络模型都有一个通用的架构。称为图卷积神经网（GCNs），这些模型是**可卷积的**，因为滤波器参数在图中所有位置或者一个局部位置上都可以共享。

### 分类

图神经网络可以分为图卷积神经网络（GCN），图注意力网络（GAT，缩写为了跟GAN区分），Graph LSTM等等，本质上还是把文本图像的那一套网络结构技巧借鉴过来做了新的尝试

### 主要思想

GCN 的主要思想是取所有邻居节点特征（包括自身节点）的加权平均值。度低的节点获得更大的权重。之后，我们将得到的特征向量通过神经网络进行训练

我们可以堆叠更多的层数来使 GCN 更深。考虑深度 GCNs 的残差连接。通常，我们会选择 2 层或 3 层的 GCN。

数学笔记：当看到对角线矩阵时，要想到矩阵缩放

### 层的数量及其含义

层数是指节点特征能够传输的最远距离。例如，在 1 层的 GCN 中，每个节点只能从其邻居那里获得信息。每个节点收集信息的过程是独立进行的，对所有节点来说都是在同一时间进行的。

当在第一层的基础上再叠加一层时，我们重复收集信息的过程，但这一次，邻居节点已经有了自己的邻居的信息（来自上一步）。这使得层数成为每个节点可以走的最大跳步。所以，这取决于我们认为一个节点应该从网络中获取多远的信息，我们可以为#layers 设置一个合适的数字。但同样，在图中，通常我们不希望走得太远。设置为 6-7 跳，我们就几乎可以得到整个图，但是这就使得聚合的意义不大。
![收集目标节点 i 的两层信息的过程](https://static.leiphone.com/uploads/new/sns/article/202009/1599636335287944.png)

## 数学基础

### 拉普拉斯矩阵

在数学领域图论中，拉普拉斯矩阵，有时也被称为导纳矩阵，基尔霍夫矩阵或离散拉普拉斯，是矩阵 A 的代表性曲线图。拉普拉斯矩阵可用于查找图的许多有用属性。

### 傅里叶变换

傅里叶变换是一种线性积分变换，用于信号在时域（或空域）和频域之间的变换，经傅里叶变换生成的函数 $\hat{f}$ 称作原函数 $f$ 的傅里叶变换、亦称频谱。在许多情况下，傅里叶变换是可逆的，即可通过 $\hat{f}$ 得到其原函数 $f$。

一般情况下，若“傅里叶变换”一词不加任何限定语，则指的是“连续傅里叶变换”（连续函数的傅里叶变换）。定义傅里叶变换有许多不同的方式。本文中采用如下的定义：（连续）傅里叶变换将可积函数 $f:\R \rightarrow \Complex$ 表示成复指数函数的积分或级数形。

离散傅里叶变换
为了在科学计算和数字信号处理等领域使用计算机进行傅里叶变换，必须将函数 xn 定义在离散点而非连续域内，且须满足有限性或周期性条件。

## 提取拓扑图的空间特征的两个主流方法

GCN 的本质目的就是用来提取拓扑图的空间特征，在 vertex domain(spatial domain)和 spectral domain 实现目标是两种最主流的方式

### vertex domain

顾名思义：提取拓扑图上的空间特征，那么就把每个顶点相邻的 neighbors 找出来。那么会遇到两个问题

1. 按照什么条件去找中心 vertex 的 neighbors，也就是如何确定 receptive field？
2. 确定 receptive field，按照什么方式处理包含不同数目 neighbors 的特征？

### spectral domain

spectral domain 就是 GCN 的理论基础了。
这种思路就是希望借助图谱的理论来实现拓扑图上的卷积操作。

## 问题

### 什么是离散卷积？

离散卷积本质就是一种加权求和

CNN 中的卷积本质上就是利用一个共享参数的过滤器（kernel），通过计算中心像素点以及相邻像素点的加权和来构成 feature map 实现空间特征的提取，当然加权系数就是卷积核的权重系数

那么卷积核的系数如何确定的呢？是随机化初值，然后根据误差函数通过反向传播梯度下降进行迭代优化。这是一个关键点，卷积核的参数通过优化求出才能实现特征提取的作用，GCN 的理论很大一部分工作就是为了引入可以优化的卷积参数。

这里的卷积是指深度学习（CNN）中的卷积，与数学中定义的卷积运算严格意义上是有区别的。

![CNN中卷积提取feature map](https://api.bbs.cvmart.net/uploads/images/201902/11/3/4bOxfeNXF6.jpg?imageView2/2/w/1240/h/0)

### GCN 中的 Graph 指什么？

CNN 是 Computer Vision 里的大法宝，可以很有效地提取空间特征。但是有一点需要注意：CNN 处理的图像或者视频数据中像素点（pixel）是排列成成很整齐的矩阵（如图 2 所示，也就是很多论文中所提到的 Euclidean Structure）

![Euclidean Structure](https://api.bbs.cvmart.net/uploads/images/201902/11/3/YYiKo0XRJs.jpg?imageView2/2/w/1240/h/0)

与之相对应，科学研究中还有很多 Non Euclidean Structure 的数据，如图 3 所示。社交网络、信息网络中有很多类似的结构。

![Non Euclidean Structure](https://api.bbs.cvmart.net/uploads/images/201902/11/3/98a8elWEjX.jpg?imageView2/2/w/1240/h/0)

实际上，这样的网络结构（Non Euclidean Structure）就是图论中抽象意义上的拓扑图。
所以，Graph Convolutional Network 中的 Graph 是指数学（图论）中的用顶点和边建立相应关系的拓扑图。

### 为什么要研究 GCN？

1. CNN 无法处理 Non Euclidean Structure 的数据，学术上的表达是传统的离散卷积（如问题 1 中所述）在 Non Euclidean Structure 的数据上无法保持平移不变性。通俗理解就是在拓扑图中每个顶点的相邻顶点数目都可能不同，那么当然无法用一个同样尺寸的卷积核来进行卷积运算。
2. 由于 CNN 无法处理 Non Euclidean Structure 的数据，又希望在这样的数据结构（拓扑图）上有效地提取空间特征来进行机器学习，所以 GCN 成为了研究的重点
3. 广义上来讲任何数据在赋范空间内都可以建立拓扑关联，谱聚类就是应用了这样的思想（谱聚类（spectral clustering）原理总结）。所以说拓扑连接是一种广义的数据结构，GCN 有很大的应用空间。

综上所述，GCN 是要为除 CV、NLP 之外的任务提供一种处理、研究的模型。
