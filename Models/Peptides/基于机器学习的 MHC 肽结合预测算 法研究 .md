---
title: 基于机器学习的 MHC 肽结合预测算法研究
subtitle: 
author:
---

主要组织相容性复合体（major histocompatibility complex，MHC）分子是免疫信息学的重要研究内容，它通过和抗原结合形成抗原肽-MHC 复合体，运送至抗原呈递细胞表面，并被 T
细胞识别，在机体免疫反应中发挥着重要的作用。

肽链序列的特征表示

结合文本语义向量和特异性得分矩阵的肽链序列的特征表示方法，利用了肽链序列上下文的联系和已知结合位点的作用，为建立模型提供基础。

传统机器学习的方法

支持向量机、随机森林和 XGBoost 

将深度学习的方法用于 MHC 结合性预测，并给出了两种基础模型。使用 CNN 模型用于提取肽链局部关键信息，RNN 模型学习肽链序列位点远距离作用关系，在此基础上提出了一种融合模型 C-BLSTM 综合二者的优势进行预测，实验结果表明，深度学习算法取得了和基准结果可比的效果并且总体优于传统机器学习算法的表现。 

## 研究背景

主要组织相容性复合体（major histocompatibility complex，MHC）是存在于大部分动物基因组中的一个基因家族，与免疫系统密切相关，定位于人与动物某对染色体的特定区域，具有丰富的多态性和多基因性。

人类的 MHC 分子称为 HLA（human leukocyte antigen，HLA），位于人体第 6 号染色体，在免疫应答的启动和调节中起着重要的作用。

在免疫系统中，抗原处理（antigen processing）是体内
细胞收集抗原、将其降解为肽段的过程，而抗原呈递（antigen presentation）则是将处理过的抗原肽段展示到细胞表面，从而便于 T 细胞识别的过程。

MHC 分子分布在细胞表面，外来抗原被抗原呈递细胞摄取和处理后，必须与  MHC 分子的肽结合区结合形成抗原肽—MHC  分子复合体，也叫表位（epitope）或抗原决定簇（antigenic determinant），该复合体经转运表达于抗原呈递细胞的表面，才能
T 淋巴细胞识别，从而启动免疫应答反应。也就是说，抗原肽段能否与特定的 MHC分子结合，是免疫系统能否识别抗原的关键。MHC 分子和特定抗原肽结合如图1.1 所示，其中 TCR 表示 T 细胞受体（T cell receptor）。 

### 肽结合预测方法可分为三大类

基于结构的方法、基于基序和位置特异性评分矩阵（PSSM）的方法和基于机器学习的方法。 

基于结构的方法利用了分子力学和分子动力学，通过分析肽和 MHC 分子之间的结构特征和能量分布来计算二者的相互作用。

基于基序和位置特异性评分矩阵的方法利用了与 MHC 分子结合的
肽的序列相似性。基序指能与 MHC 分子结合的特定位置的氨基酸残基，结合基序法考虑肽链每个位置的氨基酸作用的简单加和，简单但准确率低。位置特异性评分矩阵法是对基序法的改进，它考虑了肽链中各个位置氨基酸出现的频率，利用已知的结合特定 MHC 分子的一组肽生成一个位置权重矩阵（position weight matrix，PWM），肽链与 MHC 分子的结合性与一组和该 MHC 分子结合的已知肽的相似性决定，因此可以利用 PWM 对肽链的生物活性进行打分从而得出结果。该方法没有考虑到氨基酸之间的相互作用，并且只利用了主要位置的氨基酸作用，忽略了次要位置的氨基酸的贡献，限制了其预测效果。基于此方法的改进方法有相关研究。Dina A. Salem等人引入了数据拆分策略，使用 Kennard-Stone 算法对 PSSM 参数进行了修改，修改参数后的模型性能比原来表现出更好的效果。

机器学习

国内外已有相关学者将机器学习方法用于肽结合预测。

Hiroshi Mamitsuka 将隐马尔可夫模型的监督学习用于 MHC 结合肽，并使用此模型生成与 HLA-A2 蛋白具有高概率结合的新肽序列。Jorge Félix[
25]等
人使用随机森林算法开发了一个用于特异性预测肿瘤 T 细胞抗原的工具 TTAgP，
其在特定的 MHC 分子上实现了较高的的指标。Phophphisut Poomarin[
26]等人使用
神经网络模型开发了 MHCSeqNet，其采用自然语言处理的架构，实现了较高的预
测指标，用于筛选癌症疫苗开发中新的有效表位。Jandrlić Davorka R 等人使用基于支持向量机（SVM）和支持向量回归（SVR）两种方法建立模型，并采用不同的肽编码和加权方案，取得和已有模型可比的性能。 

本文主要研究抗原肽和 MHC 分子的结合性

免疫表位数据库 IEDB 上收集的 30 多万份多肽数据，使用机器学
习的方法进行分类

在了解多肽链结构的基础上，可以将多肽序列的是否为结
合肽的二分类问题抽象成文本的二分类问题，同时也参考了蛋白质的相关研究方法。

首先通过对数据进行两种特征编码处理，然后采用机器学习的方法进行建模，在两种深度学习模型的基础上提出融合模型，并结合了迁移学习的方法，对 MHC 肽结合性问题进行了预测。 

提出了一种综合卷积神经网络和循环神经网络的融合模型 C-BLSTM。先采用三种传统的机器学习方法对问题进行建模，然后在实现基于迁移学习的 CNN 和 RNN 模型的基础上提出了融合模型，并通过实验对其表现进行了对比，结果表明深度学习模型总体优于传统机器学习模型，融合模型总体优于 CNN 模型。 

## 基于语义向量的特征表示方法 

### One-hot 编码

两个缺点

1. 适用于编码单位较少的情况，不然会产生维度灾难
2. 它假设编码单位之间相互独立，得到的特征是稀疏的。

### 分布式编码 Distributed Representation

Hinton 1986 

分布式表示方法可以分为三大类

1. 基于矩阵的模型
2. 基于聚类的模型
3. 基于神经网络的模型 word2vec
   - CBOW: 上下文预测中心
   - Skip-gram: 中心预测上下文

### 位置特异性得分矩阵 PSSM

也称位置权重矩阵（PWM）、位置特异性权阵（PSWM）
一种表示生物学序列模式的常用方法。
PSSM 可以通过与特定的 MHC 分子结合的已知的肽序列计算得到，未知肽与 MHC 分子的结合能力由其序列与该 MHC 分子结
合的对应肽的相似性决定，相似性计算分值可以由 PSSM 计算得出，得到 PSSM 矩阵也可以作为机器学习方法中氨基酸的编码向量。 

PSSM 生成可以通过 [PSI-BLAST 在线服务网站](https://www.ebi.ac.uk/Tools/sss/psiblast) 或者下载 ncbi-blast 本地库自行生成。 

## 基于深度学习的肽结合预测算法

### 融合的特征表示方法 

本文使用的数据为氨基酸序列的一级结构形式，每个序列包含的氨基酸长度范围为 19-55，考虑到模型可能用于更长的序列预测，因此在需要固定输入的
模型中将序列长度设定为 80。

对于大多数机器学习算法，在将数据输入模型之前要将数据转化成向量格式的信息。生成的特征向量要尽量保存原序列的模式信息，这里可以采用类似
文本处理的方法生成，在 2.2 节已经对基于语义向量的特征表示方法和位置特异性得分矩阵进行了介绍，这里选择使用 Gensim 工具生成特征向量和使用 PSSM
软件生成位置特异性矩阵。 

对于使用传统机器学习的算法，可以使用词向量工具 Gensim 生成肽链的编码向量，而对于使用深度学习的算法，词向量已被集成进入网络模型当中，可
以使用更加方便的 Embedding 层进行生成，只需指定相应的尺寸参数，即可在训练网络的同时训练生成词向量。

Gensim 可以通过 Anaconda 进行安装，在 Python 中可以直接导入 Word2Vec 包，然后指定相应的参数比如向量维度（这里 选择 80）、窗口大小、学习率、选择算法等等即可，最后会得到训练好的模型和
词向量。 PSSM 生成可以在 https://ftp.ncbi.nlm.nih.gov/blast/executables/blast+/LATEST/
下载 psi，通过 Python 调用 ncbi-blast 生成 PSSM 矩阵。一个生成的 PSSM 矩阵部分内容如图 3. 1 所示。 

融合语义向量和 PSSM 矩阵的特征表示定义为：
$L(w)=L_{vec}+L_{pssm}$

### 基于深度学习的肽结合预测模型

本小节使用基于深度学习的预测模型进行多肽结合性二分类，依次介绍基于 CNN 的模型、基于 RNN 的模型和融合模型 C-BLSTM 模型。
基于 CNN 的模型只能处理固定尺寸的输入，因此需要将输入进行长度扩充，这里可以设定长度为一个用户输入的参数，根据实际需要赋值，比如一个常见的图片输入宽度
80，若模型应用于超过此长度的序列时，会进行截断处理，若序列小于此长度，则进行默认向量填充。
基于 RNN 的模型则天生适合用来处理变长序列数据。

### CNN

输入长度为大于 20 小于 80 的多肽序列，可以将长度设定为超参数，根据需要进行设置，这里选择 80。 

Input 层。输入层需要对数据进行固定长度，这部分可以放在网络模型之外进行，即小于此长度的序列进行默认字符补齐，超过长度则进行截断。Input 不属于网络的操作。

Embedding 层。即嵌入层，这里需要指定输入词典的的长度即氨基酸的种数加上默认编码，为 21，输出长度为特征向量的维数，设定为最长的序列长度，为 80。经过这一层的处里，会输出 80*80 的二维矩阵，通道数为 1。 

卷积层。这里使用了两个卷积层进行特征提取，卷积核的边长一般为3、5、7，但太小的卷积核会导致较深的网络层次，本文卷积核参数分别为 $5*5*6$ 和 $5*5*16$，步长都为 1，其中 6 和 16 表示输出通道数，经过这两个卷积层的处理，数据尺寸变成了 $76*76*6$ 和 $34*34*16$。

Batch Normal。即归一化层，这一层的作用是将输出从激活函数的饱和区拉到非饱和区以解决梯度消失问题，对数据的尺寸不产生改变。归一化层一般紧跟在卷积层之后而在激活函数之前。 

激活函数。激活函数的作用是使网络具备非线性拟合能力，激活函数不是单独的层，一般将激活函数视为和卷积层同一层，这里使用 Re LU 激活函数。 

池化层。池化层会极大的缩小数据的尺寸并提取最重要的特征，这里使用两个 $2*2$ 的池化核，池化函数使用最大池化，经过这两个池化层之后数据尺寸分别变成了 $38*38*6$ 和 $17*17*16$。 

Flatten。即通过张量拼接降维的方式将 3 维的张量拉长，变长一维的长向量，以方便后续输入全连接层进行处理，这里将 $17*17*16$ 的矩阵变成一维的 4624 长度的向量。 

全连接层。全连接层接受所有的输入，逐步的将输入尺寸缩小，提取主要信息，通过多个全连接层和激活函数之后，最终输入到一个 n 个输出的 softmax 分类器中，这里 n 取 2。 

CNN 作为经典的神经网络模型，一般可以胜任大部分的任务，但这里仍然有一些缺点，比如需要固定输入尺寸，对于较短的氨基酸序列可能会因为神经元过多而过拟合，或者对于较长的序列难以学习到规律，CNN 擅长于提取局部的信息但可能难以学习到距离稍远的氨基酸之间的关系等等。因此，本文在这个基础上又使用了 RNN 神经网络的几种变体进行了尝试。 

### RNN

RNN 是比较适合用来处理变长的或者随时间变化的序列数据，考虑到标准 RNN 容易出现的梯度爆炸和梯度消失问题，本小节使用标准 RNN 的变体 LSTM 对肽链结合性预测问题进行了尝试。

和 CNN 类似，RNN的输入也需要进行通过 Embedding 层进行编码。不同之处在于网络层，即图中
用虚线框出的部分，这里可以使用标准的 RNN，也可以使用其变体 LSTM 或者 GRU。这里不需要定义网络的输入尺寸，只需要定义特征维度（即单个字符的编码维度）、隐藏单元的维度、隐藏单元的层数等即可。为了让每个位置的氨基酸利用其左右两边的信息，这里使用双向流动的 LSTM 和 GRU 单元，即 BLSTM 和 BGRU。GRU 跟 LSTM 类似，但减少了门控单元的数量更容易训练。 

### C-BLSTM

作者将 CNN 和 LSTM 结合得到的融合模型

首先对 CNN 模型进行改进。考虑到对于新的肽链数据的预测可能不满足数据独立同分布的假设，实际的新数据可能还具有和训练集数据不同的特征。因此，引入迁移学习的方法，在 CNN 每个全连接的后面加入自适应层，使用 MK-MMD 距离以应对分布不同的数据。

## 实验结果与分析

**训练数据**
从 IEDB [数据库](http://www.iedb.org/)收集
非冗余版本（similarity reduced）的数据

**筛选标准**
HLA-A，B 和 C 亚型的 HLA I 类等位基因
肽链序列的长度不超过 50
排除与实验不一致和置信度较低的情况

**数据情况**
总共收集了 319574 条肽链数据，其中 70047 个负例，249527 个正例，正负样本比例接近 3.56：1。

**数据不平衡**
使用模型先创建一部分伪肽链序列，即在另一个数据库中随机选择一部分蛋白质序列，使用模型生成标注，同时选取高置信度的负例加入样本中。 

**测试模型性能的数据** 
IEDB 的[基准测试网站](http://tools.iedb.org/auto_bench/mhci/)，该网站数据每周更新一次基准结果，从中选取了 11 个子数据集，并将其结合力数值根据阈值转换为二进制类型。

**模型**
sklearn + tensorflow
sklearn 很多都是基于 word2vec 的

**评价指标**
分类用 AUC

### 实验方案

### SVM

对于二分类来说，SVM 仍然属于比较优秀的机器学习模型之一。 

基于 libsvm 实现，可以选择多个核函数

常用的是线性核函数和高斯核函数，当样本特征维度很小而样本数量一般大小或者数
据集线性不可分时，使用高斯核函数较好，否则使用线性核函数。

由于实验样本数量较大，高斯核函数需要两两内积计算量较大，线性核函数可以通过增加特征维度的方式来使得数据集线性可分来弥补其不足，因此本实验使用线性核函数。

SVM 对于线性不可分的情况一般选用高斯核函数来映射，但样本量较大（20000 以上）时计算复杂度很高，而线性核函数可能会限制了其分类性能。

线性核函数确定以后，SVM 的主要调节参数为松弛变量惩罚因子 C，剩余参数为默认值。

SVM 参数

| 参数名称 | 参数类型 | 参数意义 | 参数值 |
| -------- | -------- | -------- | ------ |
|C | 浮点型 | 松弛变量惩罚参数  |实验调节 |
|kernel| 枚举型  |核函数类型  |linear |
|probability | 布尔型|  是否启用概率估计  |False |
|shrinking | 布尔型  |是否采用启发式收缩 | True |
|tol  浮点型|  停止训练的误差精度 | 0.001 |
|random_state  |整型 | 伪随机数发生器的种子|  None |

C 表示模型对错误样例的容忍程度，C 越大，表示对错误分类惩罚越大，容易过拟合，C 越小则表示对错误更大的容忍度，太小则无意义。 

## RF

### XGBoost

GBoost 依赖基分类器
它的基分类器属于串行生成，后续分类器的训练依赖之前的分类器，如果数据出现了异常值，模型可能需要较多的分类器才能达到收敛。

### 模型表现

模型在测试集上的表现不如验证集
主要原因是部分测试集上的数据分布和肽链序列特征相差较大 = 过拟合 = 泛化性差
可以尝试迁移学习

### 编码分析

PSSM 在几个小数据集上表现略优于 word2vec，但在大数据集上表现略劣于 word2vec。
可能原因是 word2vec 是从肽链序列库中的序列上下文得出，其提取了多种不同的肽链的特征，具有更强的泛化性能。而 PSSM 是由已知 MHC 结合的肽链的特定位点得出的，不能很好地表示未知的肽链特征，因而表现较差。

**融合编码**综合PSSM 已有的（蛋白质）信息，再加上 word2vec 的肽链语料库信息。

### 深度学习模型

基于 CNN 的模型对小样本的数据集表现较好，其对特征提取的能力很强，但对后几个等位基因数据量较多的肽链序
列表现一般，可能是 CNN 值注意提取到局部特征，而没有关注远距离的氨基酸关系。但用其提取特征应该是一个比较好的方式。 
基于 RNN 的模型总体表现比其他两个模型略胜一筹，它发挥了处理序列数据之间上下文的关系的优势，以及 BLSTM 提
取远距离特征的能力，在各个数据集上表现相对更稳定，并且接近基准最优值，但提取特征能力要弱于 CNN。 

融合模型总体上优于单独的 CNN 模型，它结合了两者的优势，使用了 CNN 网络提取氨基酸局部的信息，同时防止过拟合和提高泛化性引入了自适应层，使用 BLSTM 提取了序列双向的远距离特征的关系，综合得到的特征更能代表肽链的结合能力，泛化性更强，在 4 个数据集上取得了最好效果。































