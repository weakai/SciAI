---
title: FixMatch
date: 2022-7-18
tags: []
---

FixMatch: Simplifying Semi-Supervised Learning withConsistency and Confidence

这是一个非常简单的算法。实际上是 pseudo label（伪标签） 和 consistence regularization（一致性正则化）。

1. 利用弱数据增广图像生成伪标签
2. 利用阈值，保留预测置信度更高的伪标签
3. 将产生的伪标签作为label对强增广的图像利用正常交叉熵进行训练

## 主要思想

针对目前基于伪标签技术的半监督学习算法，往往设定一个**高且固定的阈值**（例如FixMatch中所设定的阈值为 0.95），如果模型针对无标注样本的置信度超过设定的阈值，才会给其赋予一个伪标签。置信度高的置信度拥有伪标签并参与计算，这样可以滤除大量的噪声数据标签。但是本文作者认为，这种**高且固定的阈值存在一定的问题**，会导致模型对于不同的训练状态以及不同类别的训练难度考虑不足，导致效果较差，因此提出了一种课程学习方法——**课程伪标签(Curriculum Pseudo Labeling, CPL)**。

像 FixMatch 这种固定阈值的伪标签算法存在主要的问题：

1. 在训练的过程中仅仅考虑那些高置信度的样本忽视了大量的其他低置信度样本，尤其是在训练的初期，只有少数的样本能够超过设定的阈值。
2. 这种算法没有考虑不同类别样本之间的学习难度，而是将所有的类别同等程度考虑。

为了解决这个问题，提出**课程伪标签(Curriculum Pseudo Labeling, CPL)**方法，**随着训练的过程动态的调整每个类别的阈值**（**flexible threshold**），同时没有引入 额外的参数与计算量。

## 方法详解

当前的半监督学习算法只给那些由 SSL 的一个预定义阈值截断的高置信度未标记数据赋予伪标签， 而CPL通过在不同的训练过程中通过调整阈值在不同的时间步将伪标签赋给不同的类。

**Curriculum Pseudo Labeling **方案可以在 **不需要额外验证集，不引入额外计算，不增加额外的超参数** 的情况下，实现阈值的动态调整。

#### CPL方案

一个关键假设是，当阈值较高时，一个类的学习效果可以通过其预测属于该类且高于阈值的样本数来反映。也就是样本数较少且预测置信度达到阈值的类被视为学习难度较大或学习状态较差。

![](https://pic1.zhimg.com/80/v2-2694052306ce25357a7b10d8ba246fec_720w.png)

这里，![[公式]](https://www.zhihu.com/equation?tex=%5Csigma_t%28c%29)表示第 c 类在 t 时刻的学习效果，其实就是在所有样本中对高于固定阈值且属于类别 c 的样本的数目。

从上边归一化式子可以看出，对于评估最好的类别，其缩放比例为1保持设定的最高阈值不变。比较难学习的类别其阈值将会降低，从而使其更多的样本参与到学习过程。

**归一化**操作：

![](https://pic3.zhimg.com/80/v2-31259a62372b8105d76da2c0a457cc7a_720w.jpg)

从上边归一化式子可以看出，对于评估最好的类别，其缩放比例为 1 保持设定的最高阈值不变。比较难学习的类别其阈值将会降低，从而使其更多的样本参与到学习过程。

无标注数据**损失函数：**

![](https://pic3.zhimg.com/80/v2-bb2c95138dafc7938257ce5d55152e42_720w.png)

#### 阈值 warm up

在训练的初始阶段，受模型随机初始化影响，模型很可能把数据都盲目地**预测到一个类**里去。因此采用阈值的 warm up。

## Reference

- [NeurIPS2021 半监督论文FlexMatch解读](https://zhuanlan.zhihu.com/p/430387494)