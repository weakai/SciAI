---
title: Geometric Deep Learning
date: 2022-7-18
---

**几何深度学习**，从对称性和不变性的角度，尝试对一大类机器学习问题进行统一。

因此，几何深度学习，**指的不是某一个算法**，而是在许多算法中找到一个共同点，进行概况。

深度学习（表征学习）领域的现状让人想起十九世纪的几何学情况：

**一方面**，在过去十年中，深度学习给数据科学带来了一场革命，使许多以前被认为是无法完成的任务成为可能--无论是计算机视觉、语音识别、自然语言翻译，还是下围棋。**另一方面**，现在有各种不同的神经网络架构，用于不同类型的数据，但很少有统一的原则。

因此，很难理解不同方法之间的关系。

找到算法的共性，以此为框架，作为一种思想，启发后人的算法结构设计。

#### 图重连

「图重连」突破了 GNN 的理论基础。GNN  和卷积神经网络（CNN）之间的一个重要且微妙的区别是：图既是输入的一部分，也是计算结构的一部分。传统的 GNN  使用输入的图结构来传播信息，通过这种方式获得既反映图结构又反映图上特征的表示。由于某些结构特征（「瓶颈」），一些图在信息传播方面的性能较差，导致来自太多节点的信息被压缩到一个节点彪悍尊能中，即「过压缩」。

现代 GNN  实现通过将输入图与计算图解耦（或为计算目的优化输入图）处理这种现象，这种技术称为「图重连」。重连可以采取以下形式：邻域采样、虚拟节点、连通性扩散或演化，或节点和边的 Dropout 机制。Transformer 和像 GAT 这类基于注意力的  GNN，通过为每条边分配不同的权重，有效学习新的图，可以理解为一种「软性」的重接。最后，潜图学习方法可以归入这一类，可以构建针对特定任务的图，在每一层中更新（初始状态下有位置编码、初始图，或有时根本没有图）。很少有现代 GNN 模型在原始输入图上传播信息。



## Reference

- [几何深度学习（Geometric Deep Learning）技术](https://www.cnblogs.com/wujianming-110117/p/15987866.html)
