# long-tail

类别不平衡（又称长尾问题）是指在分类问题中，类别之间的表示质量/样本数量不平等。类别不平衡在实践中广泛存在，例如金融欺诈检测、入侵检测、医疗辅助诊断等罕见模式识别任务。类的不平衡往往会导致传统机器学习算法的预测性能下降。类别不平衡学习旨在解决这一问题，即从不平衡的数据中学习一个无偏的预测模型。

#### [NeurIPS 2020 | 数据类别不平衡/长尾分布？不妨利用半监督或自监督学习](https://zhuanlan.zhihu.com/p/259710601)

不同于之前对于长尾分布研究方法，我们从 “the value of labels”，即这些本身就不平衡的数据标签具有的“价值”这一思路去考虑。
与理想情况下平衡的标签不同，这些不平衡的数据标签存在一个非常有趣的 dilemma。
一方面，这些标签提供了非常珍贵的监督信息。
有监督的学习通常都比无监督的学习在给定任务上具有更高准确性，因此即使不平衡，这些标签也拥有“正面价值”。
但是另一方面，由于标签非常不平衡，训练模型的过程中可以非常自然的强加上 label bias，从而使得最后的决策区域很大程度上被 major class 影响；
这样的结果又证明了不平衡标签的“负面价值”。

作为总结，在不平衡的训练集中，这些标签就像一把双刃剑；想要得到更好的结果，一个非常重要的问题就是如何最大程度的利用不平衡标签的“价值”？

于是，我们尝试系统性的分解并且分别分析上述两种不同的角度。我们的结论表明对于正面的和负面的角度，不平衡标签的价值都可被充分利用，从而极大的提高最后分类器的准确性：

从正面价值的角度，我们发现当有更多的无标签数据时，这些不平衡的标签提供了稀缺的监督信息。
通过利用这些信息，我们可以结合半监督学习去显著的提高最后的分类结果，即使无标签数据也存在长尾分布。
从负面价值的角度，我们证明了不平衡标签并非在所有情况下都是有用的。标签的不平衡大概率会产生label bias。因此在训练中，我们首先想到“抛弃”标签的信息，通过自监督的学习方式先去学到好的起始表示形式。我们的结果表面通过这样的自监督预训练方式得到的模型也能够有效的提高分类的准确性。

半监督框架下的不均衡学习

作者从 toy-example 中得出结论
- 原始数据集的不平衡性会影响我们最后 estimator 的准确性
- 无标签数据集的不平衡性影响我们能够得到一个好的 estimator 的概率

半监督的不平衡学习框架：我们的理论发现表明，利用pseudo-label伪标签（以及训练数据中的标签信息）可以有助于不平衡学习；而数据的不平衡程度会影响学习的结果。受此启发，我们系统地探索了无标记数据的有效性。我们采用最简单的自训练（self-training）的半监督学习方法，即对无标记数据生成伪标签（pseudo-labeling）进而一起训练。准确来讲，我们首先在原始的不平衡数据集 ![[公式]](https://www.zhihu.com/equation?tex=%5Cmathcal%7BD%7D_L) 上正常训练获得一个中间步骤分类器 ![[公式]](https://www.zhihu.com/equation?tex=f_%7B%5Chat%7B%5Ctheta%7D%7D) ，并将其应用于生成未标记数据 ![[公式]](https://www.zhihu.com/equation?tex=%5Cmathcal%7BD%7D_U) 的伪标签 ![[公式]](https://www.zhihu.com/equation?tex=%5Chat%7By%7D) ；通过结合两部分数据，我们最小化损失函数 ![[公式]](https://www.zhihu.com/equation?tex=%5Cmathcal%7BL%7D%28%5Cmathcal%7BD%7D_L%2C+%5Ctheta%29+%2B+%5Comega+%5Cmathcal%7BL%7D%28%5Cmathcal%7BD%7D_U%2C+%5Ctheta%29) 以学习最终模型 ![[公式]](https://www.zhihu.com/equation?tex=f_%7B%5Chat%7B%5Ctheta%7D_%7B%5Ctext%7Bf%7D%7D%7D) 。

值得注意的是，除了self-training之外，其他的半监督算法也可以通过仅修改损失函数轻松地并入我们的框架中；同时，由于我们未指定 ![[公式]](https://www.zhihu.com/equation?tex=+f_%7B%5Chat%7B%5Ctheta%7D%7D) 和 ![[公式]](https://www.zhihu.com/equation?tex=f_%7B%5Chat%7B%5Ctheta%7D_%7B%5Ctext%7Bf%7D%7D%7D) 的学习策略，因此半监督框架也能很轻易的和现有类别不平衡的算法相结合。

从图中可以直观看出，使用未标记数据**有助于建模更清晰的类边界**，并促成**更好的类间分离**，尤其是对于尾类的样本。这样的结果也符合我们的直观理解，对于尾类样本，其所处区域的数据密度低，模型在学习过程中不能对这些 low-density 区域很好建模边界，从而造成模糊性（ambiguity）导致较差的泛化；而无标记数据则能有效提高低密度区域样本量，加上了更强的 regularization 使得模型重新更好地建模边界。

虽然通过半监督学习，模型在不平衡数据上的表现能够得到显著的提升，但是**半监督学习本身也存在一些实际应用的问题**，而这些问题在不平衡学习中可能会被进一步放大。接下来我们通过设计相应实验来系统地阐述和分析这些情况，并 motivate 接下来对于不平衡标签“负面价值”的思考和研究。

首先，**无标签数据与原始数据的相关性**对于半监督学习的结果有很大的影响。举个栗子，对于 CIFAR-10（10类分类）来说，获得的无标签数据可能并不属于原本 10 类中的任何一类（比如高山兀鹫...），这时多余的信息则可能对训练和结果造成不小影响。为了验证这一观点，我们固定无标签数据和原始训练数据有相同的不平衡比率，但是通过改变无标签数据和原始训练数据的**相关性**去构造不同的无标签数据集。**从 Figure 2 中我们可以看出，无标签数据的相关性需要达到将近 60% 以上才能过对不平衡学习有正面的帮助。**

既然原始训练数据是不平衡的，能够采集到的**无标签数据也大概率是极度不平衡的**。譬如医疗数据中，你构建了自动诊断某类疾病的数据集，其中正例（患病）很少，只占总体 1%，但因为此病得病率就在 1% 左右，即使大量搜集无标签数据，其中真正患病数据大概率还是很少。那么，在**同时考虑相关性的前提**下，如 Figure 3 所示，我们首先让无标签数据集有足够的相关性（60%），但改变无标签数据的不平衡比率。这个实验中，我们固定原始训练数据的不平衡比率为 50。可以看到对于无标签数据，当无标签数据过于不平衡（本例中不平衡比率高于50）时，利用无标签数据反而可能让结果变得更差。

上述问题在某些特定的实际不平衡学习任务中，可能是非常普遍的。比如医疗/疾病诊断的应用，对于可能获得的无标记数据，其绝大多数大概率也都是从正常样本上采集的，这首先造成了数据的不平衡；其次，即使是患病的样本，也很可能由很多其他混杂因素（confounding factors）导致，而这会降低与本身研究病症的相关性。因此，在一些很难利用半监督学习的极端情况下，我们需要完全不同的但是也行之有效的方法。非常自然的，我们接下来从不平衡标签负面价值的角度去入手，阐述另一思路 --- 自监督学习带来的好处。

- 自监督框架下的不均衡学习
  - 有很高的概率，我们能得到一个更好的分类器: 这个分类器的error probability随数据维度 ![[公式]](https://www.zhihu.com/equation?tex=d) 的增加而指数型减小。对于如今常见的高维数据（如图像)这种性质是我们希望得到的。
  - **训练数据的不平衡性会影响我们能够得到这样一个好的分类器的概率**。上文中，![[公式]](https://www.zhihu.com/equation?tex=N_%2B) 和 ![[公式]](https://www.zhihu.com/equation?tex=N_-) 代表训练数据里不同类的数量。从 ![[公式]](https://www.zhihu.com/equation?tex=2e%5E%7B-N_-d%5Cdelta%5E2%2F8%7D) 和 ![[公式]](https://www.zhihu.com/equation?tex=2e%5E%7B-N_%2Bd%5Cdelta%5E2%2F8%7D) 这两项中我们可以发现，当数据越多且越平衡，我们就有更高的概率得到一个好的分类器。
- **自监督的不平衡学习框架：**为利用自监督来克服固有的“label bias”，我们提出在长尾学习的第一阶段先放弃标签信息，并进行**自监督预训练**（self-supervised pre-training，SSP）。此过程旨在从不平衡数据集中学到更好的、与标签无关的初始化特征信息。在此阶段后，我们可以使用任何标准的训练方法，去训练得到最终的模型。由于预训练与正常训练阶段所采用的学习方法无关，因此这种策略可与任何现有的不平衡学习算法兼容。一旦自监督产生良好的初始化，网络就可以从预训练任务中受益，并最终学习到更通用的表示形式。

最后同样展示一下自监督下的定性实验结果。与之前一样，我们分别画出了训练和测试集的特征t-SNE投影。从图中不难发现，正常CE训练的决策边界会很大程度被头类样本改变，从而导致在（平衡的）测试集中尾类样本的大量“泄漏”，无法很好泛化。相比之下，使用SSP可以**保持清晰的分离效果**，并**减少尾类样本的泄漏**，尤其是在相邻的头类和尾类之间。这样的结果同样也能直观理解：自监督学习通过额外的task来约束学习过程，对数据空间的结构学习的更完整、提取的信息更全面，相比不平衡的标签信息带来的语义信息的不平衡，其能有效减轻网络对高层语义特征的依赖，以及对尾部数据的过拟合，学到的特征表示会更鲁棒易泛化，从而在下游任务中表现更好。

最后总结一下本文，我们首次通过半监督和自监督这两个不同的viewpoint去尝试理解和利用不平衡的数据（标签），并且验证了这两种框架均能提升类别不均衡的长尾学习问题。我个人还是挺喜欢这篇文章的，有很直观的理论分析与解释，以及用非常**简洁**并且**通用**的框架去提升长尾分布下的学习任务。拿一位给我们很高分数的reviewer的原话，“The results could be of interest to even broader area of different applications”，即不只是局限于文中做的几个academic datasets，而对于现实中许多常见的imbalance或long-tail的任务，都是能即插即用，或是对如何有效收集无标签数据提供一些insight的。


## References

- [Awesome | Curated imbalanced learning papers, codes, and libraries](https://github.com/ZhiningLiu1998/awesome-imbalanced-learning)