soft 回归

> 多分类回归，每一类返回一个概率

## 感知机

### 简单感知机

只能用于二分类

等价于批量为 1 的梯度下降算法，并使用 max 损失函数

收敛定理：必然能完成二分类

XOR 问题

> 感知机不能拟合 XOR 函数，它只能产生线性分割面
> 感知机 -> 多层感知机

### 多层感知机 mlp

一个线性分割面分不了，再来几个

等价于 soft 回归加了一层隐藏层

隐藏层的大小是超参数，对于多隐藏层，层数也是超参数

![](https://cdn.jsdelivr.net/gh/xxzhai123/img/img2021-07-27%2015-08-21%20%E7%9A%84%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE.png)

为什么要加激活函数 $\sigma()$

> 不加的话输出层 o 仍然为线性函数，因此这个模型仍然是简单的线性模型。

层呢 带权重，带激活函数，带计算过程，包括输出，不包括输入

机器学习是统计的计算机实现

SVM 替代了 感知机，为什么？调参太难了。SVM 优化容易，使用简单，SVM 是数学家写的，代码很漂亮，效果是差不多的。SVM 在两千年的时候非常流行

深度学习 = 很多隐藏层
大浅层学习 = 一层隐藏层，该层的大小相当大

同样效果下，训练的难度：深度学习 < 大浅层学习
大浅层学习，容易过拟合

隐藏层的数量应该是 2 的倍数，有利于计算

数据科学家 80% 时间选数据，20% 时间调参。

## 训练误差与泛化误差

就像模拟考和高考

我们关心泛化误差

验证数据集一定不能和训练数据集混在一起

### 过拟合与欠拟合

![](https://cdn.jsdelivr.net/gh/xxzhai123/img/img2021-07-27%2019-23-55%20%E7%9A%84%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE.png)

如何选模型容量

![](https://cdn.jsdelivr.net/gh/xxzhai123/img/img2021-07-27%2019-25-36%20%E7%9A%84%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE.png)

### 估计模型容量

可以估计，但不同类型模型之间难对比估计

因素
参数个数，参数值的选择范围



## SVM 与 神经网络

SVM 不支持大量数据，调的东西不多，只能调 Kernel 的一些参数。
神经网络本身是一种语言，很玄的，可编程性。

