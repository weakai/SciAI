---
title: Adaboost
---

AdaBoost 算法的全称是自适应 Boosting（Adaptive Boosting），是一种二分类器，是一种集合技术，它用弱分类器的线性组合构造强分类器。

AdaBoost 是第一个为二进制分类开发的真正成功的增强算法。

现代助推方法建立在 AdaBoost 上，最着名的是随机梯度增强机。

AdaBoost 用于短决策树。在创建第一个树之后，每个训练实例上的树的性能用于加权创建的下一个树应该关注每个训练实例的注意力。难以预测的训练数据被赋予更多权重，而易于预测的实例被赋予更少的权重。模型一个接一个地顺序创建，每个模型更新训练实例上的权重，这些权重影响序列中下一个树所执行的学习。构建完所有树之后，将对新数据进行预测，并根据训练数据的准确性对每棵树的性能进行加权。

Adaboost 的 7 个优缺点

-   很好的利用了弱分类器进行级联；
-   可以将不同的分类算法作为弱分类器；
-   AdaBoost具有很高的精度；
-   相对于bagging算法和[Random Forest](https://easyai.tech/ai-definition/random-forest/)算法，AdaBoost充分考虑的每个分类器的权重；

-   AdaBoost迭代次数也就是弱分类器数目不太好设定，可以使用交叉验证来进行确定；
-   数据不平衡导致分类精度下降；
-   训练比较耗时，每次重新选择当前分类器最好切分点；