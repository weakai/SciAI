# 流行学习

## 什么是流形？

流形（manifold）是几何中的一个概念，它是高维空间中的几何结构，即空间中的点构成的集合。
可以简单的将流形理解成二维空间的曲线，三维空间的曲面在更高维空间的推广。
下图是三维空间中的一个流形，这是一个卷曲面：

![](https://pic3.zhimg.com/80/v2-7dcc5b2aa752a5af8f508202c6862f52_720w.jpg)

2 维空间中的曲线，3 维空间中的曲线可以看做是 2 维和 3 维空间中的 1 维流形，因为曲线是 1 维的。
而 3 维空间中的曲面可以看做是 2 维的流形，因为曲面是 2 维的。n 维空间中的 m 维流形就是具有 m 维几何形状的一个子集，在这里，m 小于 n。
在一般的流形学习算法中，我们并没有过多的用到微分几何，拓扑等复杂的数学理论，因此在本文中我们不对流形的数学理论做过多的阐述。

## 什么是流形学习？

流形学习的观点：
认为我们所观察到的数据实际上是由一个低维流形映射到高维空间的。
由于数据内部特征的限制，一些高维中的数据会产生维度上的冗余，实际上这些数据只要比较低的维度的维度就能唯一的表示。
所以直观上来讲，一个流形好比是一个 d 维的空间，在一个 m 维的空间中（m>d）被扭曲之后的结果。
需要注意的是流形不是一个形状，而是一个空间。
举个例子，比如说一块布，可以把它看成一个二维的平面，这是一个二维的空间，现在我们把它扭一扭(三维空间),它就变成了一个流形，
当然不扭的时候，它也是一个流形，欧氏空间是流形的一种特殊情况。

流形具有在局部和欧氏空间同胚的空间，也就是局部具有欧氏空间的性质，能用欧式距离来进行距离计算。
这就给降维带来了很大的启发，若低维流形嵌入到了高维空间，此时样本在高维空间的分布虽然复杂，但在局部上仍具有欧氏空间的性质，因此可以在局部建立降维映射关系。
然后再设法将局部映射推广到全局。而且当数据被降维到二维和三维时可以进行可视化，因此流形学习也可以被用于可视化。

流形学习是一类借鉴了拓扑流形概念的降维方法。
“流形”是指的是连在一起的区域，数学上，它指的是一组点，且每个点都有其邻域。
给定任意一个点，其流形局部看起来像是欧几里得空间。
换言之，它在局部空间有欧式空间的性质，能用欧式空间来进行距离计算。
因此，很容易地在局部建立降维映射关系，然后再设法将局部关系推广到全局，进而进行可视化展示。

很多应用问题的数据在高维空间中的分布具有某种几何形状，即集中在某个低维的流形附近。
对于前面所说的 32x32 的手写数字图像，数字 7 的图像在 1024 维空间中应该聚集在某一个形状的几何体周围（如带状区域，球面），其他的类别也是如此。
流形学习（manifold learning）假设数据在高维空间的分布位于某一更低维的流形上，基于这个假设来进行数据的分析。
对于降维，要保证降维之后的数据同样满足与高维空间流形有关的几何约束关系。
除此之外，流形学习还可以用实现聚类，分类以及回归算法。

假设有一个 N 维空间中的流形 M，即 M 为 N 维欧氏空间的一个真子集：
![](https://pic3.zhimg.com/80/v2-fa7f56b4e9bd290ad71278b5cb7a1042_720w.jpg)
流形学习降维算法要实现的是如下映射：
![](https://pic4.zhimg.com/80/v2-b210e868c78f9787eb6497ebeb73ddf7_720w.jpg)

其中 n<<N。
即将 N 维空间中流形 M 上的点映射为 n 维空间中的点。
下面介绍几种典型的流形降维算法，包括局部线性映射，拉普拉斯特征映射，局部保持投影，等距映射。 

## 流形学习有什么用？

第一个方面：高维空间有冗余，低维空间没冗余。
也就是说，流形可以作为一种数据降维的方式。
传统很多算法都是用欧氏距离作为评价两个点之间的距离函数的。
举个例子，在地球仪上从北京到上海需要一个能够弯曲的软软的尺子来测量两个点的距离。
_显然对于“从北京到上海”的距离这件事，我们关注的是把三维地球展开成二维空间，然后测量地表距离，而不是三维空间中的球面上两点的欧氏距离。_

从上面可以看出，流形空间上的可以用欧氏距离，不代表低维流形所展成的高维空间中可以使用欧氏距离进行衡量。
但实际上很多时候，尽管是高维空间，但出于简便，我们仍然近似使用欧氏距离。但通常来说效果都不会太好。
不过我们通过一些变换，将原始的高维空间的数据映射到低维流形空间然后再使用欧式距离衡量，或者干脆用一种能够在高维空间更准确地度量距离的距离函数来替代欧氏距离。
这样能取得更加合理的距离度量结果。

第二方面:
流形能够刻画数据的本质。
也就是说，既然学习到了”将数据从高维空间降维到低维空间，还能不损失信息”的映射，
那这个映射能够输入原始数据，输出数据更本质的特征(就像压缩一样，用更少的数据尽可能地表示原始数据)。
这一方面和深度学习很像，深度学习的主要特点就是“特征学习”。
所谓的特征就是能够表示数据本质的内容。

## 实现

### 编码与解码器

自动编码器(autoencoder)是非常基本的深度学习模型，用来学习流形结构。

### 生成模型GAN

生成模型是深度学习的一个典型应用。输入一张低维的白噪声，输出一张逼真的人脸图像。这在传统框架下是匪夷所思的：我们平白无故地变出一张人脸。但在流形框架下非常简单。

深度学习的成功应该归功于数据自身具有的内在规律：高维数据分布在低维流形附近，流形上具有特定概率分布，同时归功于深度学习网络强大的逼近非线性映射的能力。
深度学习计数可以从一类数据中提取流形结构，将整体先验知识用流形来表达，具体而言就是编码解码映射，隐含在神经元的权重中。
深度学习的强大能力来源于某类知识的整体表达，而传统算法只能利用同一类别的局部有限知识。
同时深度学习基于底层流形的选择，很多算法移植性依赖于底层流形的替换。

## Links

- [流形学习概述](https://zhuanlan.zhihu.com/p/40214106)
- [流形学习 (Manifold Learning) | 有流形前置知识](https://leovan.me/cn/2018/03/manifold-learning/)
- [深度学习与流形学习（一）](https://yifdu.github.io/2018/11/25/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B5%81%E5%BD%A2%E5%AD%A6%E4%B9%A0%EF%BC%88%E4%B8%80%EF%BC%89/)