---
title: 可重现性
author: seeyou
---

## 确定性设置

### 随机种子设置

随机函数是最大的不确定性来源，包含了模型参数的随机初始化，样本的 shuffle。

```python
# PyTorch
import torch
torch.manual_seed(0)

# python
import random
random.seed(0)

# Third part libraries
import numpy as np
np.random.seed(0)
```

CPU 版本下，上述随机种子设置完成之后，基本就可实现实验的可复现了。

### GPU算法确定性实现

GPU 算法的不确定来源有两个
- CUDA convolution benchmarking
- nondeterministic algorithms

CUDA convolution benchmarking 是为了提升运行效率，对模型参数试运行后，选取最优实现。不同硬件以及 benchmarking 本身存在噪音，导致不确定性。

nondeterministic algorithms：GPU 最大优势就是并行计算，如果能够忽略顺序，就避免了同步要求，能够大大提升运行效率，所以很多算法都有非确定性结果的算法实现。

通过设置 use_deterministic_algorithms，就可以使得 pytorch选择确定性算法。

所以在测试的时候为了效率，可以不用设置 GPU 的随机性。

```python
torch.backends.cudnn.benchmark=False  # 不需要 benchmarking

torch.use_deterministic_algorithms(True)  # 选择确定性算法
```

### 多线程样本读取的随机确定

```python
# 设置每个读取线程的随机种子
def seed_worker(worker_id):
    worker_seed = torch.initial_seed() % 2**32
    numpy.random.seed(worker_seed)
    random.seed(worker_seed)

g = torch.Generator()
# 设置样本 shuffle 随机种子，作为 DataLoader 的参数
g.manual_seed(0)

DataLoader(train_dataset,
           batch_size=batch_size,
           num_workers=num_workers,
           worker_init_fn=seed_worker,
           generator=g,)

```

## 参考

- [PyTorch 可复现/重复实验的相关设置]()