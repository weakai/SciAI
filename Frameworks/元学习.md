---
title: Meta Learning
---

## 0 基础

### 0.1 元学习与小样本学习

元学习目前主要针对小样本学习问题， 元学习训练和测试都以少样本任务为基本单元，每个任务拥有各自的训练数据集和测 试数据集，也称为支持集和查询集。元学习 在训练阶段使用大量少样本任务进行训练，且在测试阶段可产生较好的效果。为实现这一点，在元学习模型训练阶段和测试阶段所使用的数据均为只含有小样本数据的任务。因为元学习的目标是通过在训练数据上的学习掌握快速学习新任务能力，因此**元学习在训练时将整个任务集看作训练样例。**

Zero-shot Learning, Few-shot Learning, One-shot Learning 是目前元学习主要解决的三个问题。

### 0.2 元学习与数据规律的探索模式

而传统的深度学习方法虽然功力强大，但是框架无外乎都是从头开始学习（训练），即 learning from scratch，对算力和时间都是更大的消耗和考验。

比如说 GANs，GANs 本身是一个特别吃数据集的模型，从某种意义上来说，数据集的好坏对最后生成效果的影响，不亚于甚至高于生成模型本身的设计对最后生成效果的影响。造成这一现象的原因是，GANs 学习的本质是拟合数据的潜分布，而数据潜分布很大程度上由训练数据所具有的样本广度和质量来决定，因此 GANs 的训练效果容易受到来自训练数据的质量的影响。

如何摆脱这种 GANs 对于数据集的过度依赖呢？一个比较好的检测方法是在少样本学习（few-shot learning）上检验模型的学习效果。但是直接用GANs架构是很难实现少样本学习的，原因是在数据量大的时候，充足的训练样本能够让判别器精准地找到真假样本的划分界线，从而让生成器拟合出精确的生成分布，但是在数据量少的时候，要想准确地拟合数据的潜分布就会变得比较困难。

![](https://img-blog.csdnimg.cn/20210118215121960.png)

Meta learning 为解决这一问题提供了比较好的方法，首先因为 meta learning 已经被证明在少样本学习上取得了较好的效果，另外 meta learning 的方法也比较符合 GANs 的学习需求。为何这么说呢？meta learning 的目标是学习如何去学习，换言之，**它能够依靠对数据集规律的探索去制定学习策略，从而将传统 GANs 的训练过程由设计模型->寻找数据->验证模型，变为寻找数据->设计模型->验证模型**，这对于我们解决 GANs 训练中的数据不匹配以及数据缺乏问题带来很大的帮助。

Meta learning 的诞生促使机器学习向另一侧面突进，以更接近人类和更具效率的方式实现人工智能，对于 GANs 来说，将 GANs 的传统训练思维，由用数据去匹配模型，转变为用模型去匹配数据，为解决生成模型的少样本学习问题提供了突破口。

Meta learning 包括 Zero-Shot/One-Shot/Few-Shot 学习，模型无关元学习(Model Agnostic Meta Learning)和元强化学习（Meta Reinforcement Learning）等。

### 0.3 元学习与终生学习

终身学习的目标是学到一个模型可以做所有的任务，有点“一招鲜吃遍天”的意味，而元学习是掌握其他任务的内在原理从而举一反三，有点“学好数理化走遍天下都不怕”的意味。用我们这一行的话来理解元学习就是，当一个程序员掌握了基本的C++、python、Java，后面不管学什么语言都能迅速掌握，这就是元学习算法的魅力。

### 0.4 元学习与迁移学习的区别

[李宏毅机器学习-47-01-ML-MAML & Reptile](https://blog.codekiller.top/2021/02/03/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/47_ML%20Meta%20Learning/)

### 0.5 元学习的训练集

在机器学习中，训练样本中的训练集称为 train set，测试集称为 test set。元学习广泛应用于小样本学习中，在元学习中，训练样本中的训练集称为 support set，训练样本中的测试集叫做 query set。

### 0.6 模型无关 Model-Agnostic

**模型无关**的意思是该方法可以用在 **CNN**，也可以用在 **RNN**，甚至可以用在 **RL** 中。但是 MAML 做的是固定模型的结构，只学习**初始化模型参数**这件事。什么意思呢？就是我们希望通过 meta-learning 学习出一个**非常好**的**模型初始化参数**，有了这个初始化参数后，我们只需要**少量的样本**就可以快速在这个模型中进行收敛。那么既然是 **learning to learn**，那么输入就不再是单纯的数据了，而是一个个的**任务**（task)。就像人类在区分物体之前，已经看过了很多中不同物体的**区分任务**（task)，可能是猫狗分类，苹果香蕉分类，男女分类等等，这些都是一个个的任务 task。那么 MAML 的输入是一个个的 task，并不是一条条的数据，这与常见的机器学习和深度学习模型是不同的。

### 0.7 N-way K-shot learning

用于**分类任务**的 MAML，可以理解为一种 **N-way K-shot learning**，N-way 指训练数据中有 N 个类别，K-shot 指每个类别下有 K 个被标记数据。

### 0.8 task

- [Model-Agnostic Meta-Learning （MAML）模型介绍及算法详解](https://zhuanlan.zhihu.com/p/57864886)

我们假设这样一个场景: 我们需要利用 MAML 训练一个数学模型模型 ![[公式]](https://www.zhihu.com/equation?tex=M_%7Bfine-tune%7D) ，目的是对未知标签的图片做分类，类别包括 ![[公式]](https://www.zhihu.com/equation?tex=P_1%EF%BD%9EP_5) （每类 5 个已标注样本用于训练。另外每类有 15 个已标注样本用于测试）。我们的训练数据除了 ![[公式]](https://www.zhihu.com/equation?tex=P_1%EF%BD%9EP_5) 中已标注的样本外，还包括另外 10 个类别的图片 ![[公式]](https://www.zhihu.com/equation?tex=C_1%EF%BD%9EC_%7B10%7D) （每类 30 个已标注样本），用于帮助训练元学习模型 ![[公式]](https://www.zhihu.com/equation?tex=M_%7Bmeta%7D) 。我们的实验设置为 **5-way 5-shot**。

MAML 首先利用 ![[公式]](https://www.zhihu.com/equation?tex=C_1%EF%BD%9EC_%7B10%7D) 的数据集训练元模型![[公式]](https://www.zhihu.com/equation?tex=M_%7Bmeta%7D)，再在![[公式]](https://www.zhihu.com/equation?tex=P_1%EF%BD%9EP_5)的数据集上精调（fine-tune）得到最终的模型 ![[公式]](https://www.zhihu.com/equation?tex=M_%7Bfine-tune%7D) 。

此时，![[公式]](https://www.zhihu.com/equation?tex=C_1%EF%BD%9EC_%7B10%7D)即 **meta-train classes**，![[公式]](https://www.zhihu.com/equation?tex=C_1%EF%BD%9EC_%7B10%7D) 包含的共计 300 个样本，即 ![[公式]](https://www.zhihu.com/equation?tex=%7B%5Cmathcal+D%7D_%7Bmeta-train%7D) ，是用于训练 ![[公式]](https://www.zhihu.com/equation?tex=M_%7Bmeta%7D) 的数据集。与之相对的，![[公式]](https://www.zhihu.com/equation?tex=P_1%EF%BD%9EP_5) 即 **meta-test classes**，![[公式]](https://www.zhihu.com/equation?tex=P_1%EF%BD%9EP_5)包含的共计100 个样本，即 ![[公式]](https://www.zhihu.com/equation?tex=%7B%5Cmathcal+D%7D_%7Bmeta-test%7D) ，是用于训练和测试 ![[公式]](https://www.zhihu.com/equation?tex=M_%7Bfine-tune%7D) 的数据集。

根据 5-way 5-shot 的实验设置，我们在训练 ![[公式]](https://www.zhihu.com/equation?tex=M_%7Bmeta%7D) 阶段，从 ![[公式]](https://www.zhihu.com/equation?tex=C_1%EF%BD%9EC_%7B10%7D) 中随机取 5 个类别，每个类别再随机取 20 个已标注样本，组成一个 **task** ![[公式]](https://www.zhihu.com/equation?tex=%7B%5Cmathcal+T%7D) 。其中的 5 个已标注样本称为 ![[公式]](https://www.zhihu.com/equation?tex=%7B%5Cmathcal+T%7D) 的**support set**，另外 15 个样本称为 ![[公式]](https://www.zhihu.com/equation?tex=%7B%5Cmathcal+T%7D) 的 **query set**。 这个 **task** ![[公式]](https://www.zhihu.com/equation?tex=%7B%5Cmathcal+T%7D) ， 就相当于普通深度学习模型训练过程中的一条训练数据。那我们肯定要组成一个 batch，才能做随机梯度下降 SGD 对不对？所以我们反复在训练数据分布中抽取若干个这样的 **task** ![[公式]](https://www.zhihu.com/equation?tex=%7B%5Cmathcal+T%7D) ，组成一个 batch。在训练 ![[公式]](https://www.zhihu.com/equation?tex=M_%7Bfine-tune%7D) 阶段，**task**、**support set**、**query set**的含义与训练 ![[公式]](https://www.zhihu.com/equation?tex=M_%7Bmeta%7D) 阶段均相同。

## 1 元学习概述

元学习的目标是利用已学习的信息，快速适应未学习的新任务。是一种热启动学习的方式。

元学习（Meta-learning）提出的目的是针对传统神经网络模型泛化性能不足、对新种类任务适应性较差的特点。对元学习问题的研究也是提高模型的鲁棒性和泛化性的关键。

目前元学习主要表现为 提高泛化性能、获取好的初始参数、通过少量计算和新训练数据即可在模型上实现和海量训练数据一样的识别准确度，近些年基于元学习，在小样本学习领域做出了大量研究，同时为模拟人类认知，在 Zero-shot Learning 方向也进行了大量探索。

### 1.1 元学习历史

- 在机器学习盛行之前，就已产生了元学习的相关概念。当时的元学习还停留在认知教育科学相关领域，用于探讨更加合理的教学方法。

- Gene V. Glass 在 1976 年首次提出了“元分析”这一概念，对大量的分析结果进行统计分析，这是一种二次分析办法。 G Powell 使用“元分析”的方法对词汇记忆进行了研究，指出“强制”和“诱导”意象有助于词汇记忆。

- Donald B.Maudsley 在 1979 年首次提出了“元学习”这一概念，将其描述为“学习者意识到并越来越多地控制他们已经内化的感知、探究、学习和成长习惯的过程”，Maudsley 将元学习做为在假设、结构、 变化、过程和发展这 5 个方面下的综合，并阐述了相关基本原则。
- BIGGS J.B 将元学习描述为 “意识到并控制自己的学习的状态”，即学习者对学习环境的感知。
- P Adey 将元学习的策略用在物理教学上， Vanlehn K 探讨了辅导教学中的元学习方法。
- P.Chan 提出的元学习是一种整合多种学习过程的技术，利用元学习的策略组合多个不同算法设计的分类器，其整体的准确度优于任何个别的学习算法。
- HilanBensusan 提出了基于元学习的决策树框架。Vilalta R 则认为元学习是通过积累元知识动态地通过经验来改善偏倚的一种学习算法。

### 1.2 元学习定义

Meta-Learning 目前还没有确切的定义，一般认为一个元学习系统需结合三个要求: 系统必须包含一个学习子系统; 利用以前学习中提取的元知识来获得经验，这些元知识来自单个数据集或不同领域; 动态选择学习偏差。

一般来说，元学习就是学会学习的学习。当前研究也多以在小样本 数据上识别准确率作为实验衡量标准。

### 1.3 元学习研究方向

- 基于度量学习的方法
- 基于泛化性较强的初始化的方法(进展较多)
  - 模型无关元学习算法 MAML 及其改进
- 基于优化器
  - 针对传统 神经网络模型迭代速度慢、易过拟合的特性， 提出将梯度下降过程替代为单独的神经网 络模型，使用单独神经网络对梯度进行更准 确、迅速的更新，以达到快速适应的目的。
- 基于额外外部存储
- 基于数据增强的方法
  - 基于数据增强的元学习模型通过为小样本任务增加额外的样本来解决元学习中数据缺乏的问题。该类模型具有较好的通用性，可以与其它元学习方法进行结合，提高这些方法的性能。

### 1.4 元学习模型

元学习学习初始化参数的代表作是 MAML（Model-Agnostic-Meta-Learning）。
它专注于提升模型整体的学习能力，而不是解决某个具体问题的能力，训练时，不停地在不同的任务上切换，
从而达到初始化网络参数的目的，最终得到的模型，面对新的任务时可以学习得更快。

### 1.5 元学习研究方法

#### 1.5.1 基于度量的元学习方法

- 孪生网络
- 注意力机制匹配网络
- 原型网络
- 关系网络用于小样本比较学习
- 任务依赖的自适应度量提高少样本分类

#### 1.5.2 基于强泛化性的初始化参数元学习方法

- 模型无关层循环元学习框架算法
- 迁移元学习 MAML
- 不稳定环境条件下元学习的持续适应算法

#### 1.5.3 基于贝叶斯理论的元学习方法

- 基于 MCMC 的元学习
- 基于变分贝叶斯的元学习方法
- 使用上下文参数快速适应元学习算法 CAVIA

#### 1.5.4 基于梯度优化器的元学习方法

- 元学习者替代微分梯度下降

#### 1.5.5 基于外部记忆单元的元学习方法

- 使用记忆增强的模型
- surprise-based 的记忆方法
- 记忆匹配网络模型

#### 1.5.6 基于数据增强的元学习方法

- MetaGAN 对抗模型
- 特征幻化模型
- CPAAN 模型
- Imaginary data 模型

### 1.6 元学习的属性

- 自适应性
  - 要求元学习算法在面对不同的任务时都能有较好的表现
- 进化性
  - 深度学习侧重于建模我们已知的知识，而进化算法则专注于创建新的知识
- 可解释性
  - 元学习通过利用先验信息可以把部分不可解释的问题转化为可解释问题，研究元学习，是研究深度学习可解释性自然的方法。
- 连续性: 持续学习
- 可扩展性

### 0.1. 元学习的基本问题

[元学习相关知识](https://mp.weixin.qq.com/s/QLzdW6CMkcXWQbGjtOBNwg)

#### 0.1.1. 元知识的表征 meta-representation

元知识应该如何进行表征, 即学习什么的问题。

#### 0.1.2. 元学习器 meta-optimizer

如何选择学习算法进行优化，也就回答了元学习中的如何学习的问题。

#### 0.1.3. 元目标 meta-objective

朝着怎样的目标去进行学习？这回答了元学习中为什么要这样学习的问题。

### 0.2. 相关研究领域

#### 0.2.1. 迁移学习

迁移学习（transfer learning）强调从已有任务中学习新任务的思维。
与 meta-learning 相比，迁移学习更强调的是这种学习问题，而 meta-learning 则更侧重于学习方法。
因此，二者不是完全没有联系，也并不是完全相等，取决于看待问题的角度。
在很多情况下，二者的终极目标是一致的。

#### 0.2.2. 领域自适应和领域泛化

Domain adaptation 和 domain generalization 这两种学习模式是迁移学习的子集。
与 meta-learning 显著区别的是，二者没有 meta-objective，也就是说，没有 bi-level 优化的过程。
当然最近有一些工作试图将 meta-learning 引入来解决这两个领域的问题。

#### 0.2.3. 终身学习和持续学习

终身学习（lifelong learning）和持续学习（continual learning）强调在一个任务上进行连续不断地学习，
而 meta-learning 则侧重于在多个任务上学习通用的知识，有着显著区别。

#### 0.2.4. 多任务学习

多任务学习（multi-task learning）指从若干个相关的任务中联合学习出最终的优化目标。
Meta-learning 中的任务是不确定的，而多任务中的任务就是要学习的目标。

#### 0.2.5. 多任务学习

严格来说，超参数优化（hyperparameter optimization）侧重学习率、网络架构等参数的设计，其是 meta-learning 的一个应用场景。

#### 0.2.6. 其他相关研究领域

meta-learning 还与「贝叶斯层次优化」（Hierarchcal Bayesian model）和「AutoML」有着相近的联系，
但这些模型的侧重和表征点，与 meta-learning 有所不同。特别地，贝叶斯模型从生成模型的角度，为 meta-learning 提供了一个有效的看问题角度。

### 元学习 and NAS

学习网络结构：神经网络的结构设定是一个很头疼的问题，网络的深度是多少，每一层的宽度是多少，每一层的卷积核有多少个，每个卷积核的大小又该怎么定，
需不需要 dropout 等等问题，到目前为止没有一个定论或定理能够清晰准确地回答出以上问题，所以神经网络结构搜索 NAS 应运而生。
归根结底，神经网络结构其实是元学习地一个子类领域。
值得注意的是，网络结构的探索不能通过梯度下降法来获得，这是一个不可导问题，一般情况下会采用强化学习或进化算法来解决。

### Meta Learning and Reinforcement Learning

### Meta Learning and Transfer learning

元学习更偏重于任何和数据的双重采样， 任务和数据一样是需要采样的，而学习到的 F(x) 可以帮助在未见过的任务 f(x) 里迅速建立 mapping。

### Learn to Learn to Learn 问题

learn to learn: model learn its weights
Learn to Learn to Learn: learn models

### F 函数黑盒化想法

另外一个值得研究的领域是 F 函数的黑盒化想法。
因为，当前 F 学到的策略是透明的，并且人为限制了策略的内容，所以其结果不一定是机器学习能产生的最优结果。
如果我们减少人为的影响，将 F 和封装成一个更大的目标 H，让机器自己去学习 F 和的关系，
其中 H 的输入是训练资料+测试资料，输出是测试资料的预测结果，或许能让机器学习到更好的结果。

这方面已经有一些应用在尝试，譬如人脸辨识领域——输入一堆人脸库和一张测试人脸，输出预测该人脸是否是人脸库中的人脸。

## 元学习的分类/方法

1. 基于记忆 Memory 的方法: 通过以往的经验来学习，那就可以通过在神经网络中添加 Memory 来实验。
2. 基于预测梯度的方法: 让神经网络利用以往的任务学习如何预测梯度，这样面对新的任务，只要梯度预测的准，那么学习就会快。
3. 利用 Attention 注意力机制: 训练一个 Attention 模型，在面对新任务时，能够直接的关注最重要部分。
4. 借鉴 LSTM 的方法: 利用 LSTM 的结构训练处一个神经网络的更新机制，输入当前网络参数，直接输出新的更新参数 
5. 基于 RL 的 Meta Learning 方法
6. 通过训练一个 base model 的方法，能同时应用到监督学习和增强学习上
7. 利用 WaveNet 的方法
8. WaveNet 的网络每次都利用了之前的数据，那么能否照搬 WaveNet 的方式来实现 Meta Learning 呢? 就是充分利用以往的数据。 
9. 预测 Loss 的方法: 如果有更好的 Loss，那么学习的速度也会更快，因此，可以构建一个模型利用以往的任务来学习如何预测 Loss

## 元学习训练

元学习分为两个阶段，阶段一是训练任务训练；阶段二为测试任务训练。

## 笔记

二阶导数
coordinate sharing: 

weight share:
- 降低得到 reward 的时间

数更新策略
PowerSign

Activation Function
Swish
- Swish（β=1.0）的形状有点像 Relu 和 Leaky Relu 的结合

用于优化神经网络模型的元学习器的行为和循环神经网络类似。

## Links

### 必读

- [李宏毅机器学习-47-01-ML-MAML & Reptile](https://blog.codekiller.top/2021/02/03/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/47_ML%20Meta%20Learning/)
- [[meta-learning] 对MAML的深度解析](https://zhuanlan.zhihu.com/p/181709693)

### 参考

- [一文入门元学习（Meta-Learning）（附代码）](https://zhuanlan.zhihu.com/p/136975128)
- [一文通俗讲解元学习（Meta-Learning）| paperweekly](https://posts.careerengine.us/p/619646807a116821ebf7b5af)
- [元学习（Meta Learning）学习笔记](https://www.gwylab.com/note-meta_learning.html)
- [初探元学习（Meta-Learning）](https://www.jianshu.com/p/0673fc7d7760)
- 李凡长; 刘洋; 吴鹏翔; 董方; 蔡奇; 王哲. 元学习研究综述. 计算机学报 2021, 44 (02), 422–446.