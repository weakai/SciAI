---
title: Curriculum Labeling
---

Curriculum Labeling (CL)，在每个自训练周期之前重新启动模型参数，优于伪标签 (PL)。

Pseudo-Labeling (PL) 通过将伪标签应用于未标记集中的样本以在自训练周期中进行模型训练。 Curriculum Labeling (CL)中，应用类似课程学习的原则，通过在每个自学习周期之前重新启动模型参数来避免概念漂移。该论文发布在 2021 AAAI 。

![](https://pic1.zhimg.com/80/v2-17849125595e828de678e7668ac69bc4_720w.jpg)

伪标签可以认为是未标记数据的目标类，就好像它们是真正的标签一样。伪标签是通过选取网络为每个未标记样本预测的最大预测概率的类来实现的。伪标签使用带有 Dropout 的微调阶段，可以将预训练的网络以有监督的方式同时使用标记和未标记的数据进行训练。

### Curriculum Labeling (CL)

![](https://pic1.zhimg.com/80/v2-af22521ae732b4791936e269f4a24204_720w.jpg)

模型在标记样本上进行训练。然后该模型用于预测和分配未标记样本的伪标签。预测概率分数的分布用于选择伪标记样本的子集。使用标记和伪标记样本重新训练新模型。通过使用这个新模型重新标记未标记的样本来重复这个过程。 当训练期间使用数据集中的所有样本时，该过程停止。

具体来说，百分位分数用于决定添加哪些样本。上面的算法显示了模型的完整流程，其中 percentile (X, Tr) 返回第 r 个百分位的值。r 的值从 0% 到 100% 以 2 为单位递增。当伪标记集包含整个训练数据样本(r=100%)时，重复过程终止。

数据由 N 个有标记的样例(Xi, Yi)和 M 个无标记的样例 Xj 组成。设 H 是一组假设H θ，其中H θ∈H，其中H θ∈H表示一个映射X到Y的函数。设Lθ(Xi)表示给定例子Xi的损失。为了选择具有最低可能误差的最佳预测器，公式可以用正则化经验风险最小化(ERM)框架解释。

![](https://pic4.zhimg.com/80/v2-7409ebaf98ea27bd9bf8ce2f4bd015b3_720w.jpg)



## Reference

- [Curriculum Labeling：重新审视半监督学习的伪标签](https://zhuanlan.zhihu.com/p/530860794)