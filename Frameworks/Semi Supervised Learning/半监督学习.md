---
title: 半监督学习
subtitle: semi-supervised Learning
---

在有标签数据+无标签数据混合成的训练数据中使用的机器学习算法吧。一般假设，无标签数据比有标签数据多，甚至多得多。

## 半监督学习算法

**简单自训练**（simple self-training）：用有标签数据训练一个分类器，然后用这个分类器对无标签数据进行分类，这样就会产生伪标签（pseudo label）或软标签（soft label），挑选你认为分类正确的无标签样本（此处应该有一个**挑选准则**），把选出来的无标签样本用来训练分类器。

**协同训练**（co-training）：其实也是 self-training 的一种，但其思想是好的。假设每个数据可以从不同的角度（view）进行分类，不同角度可以训练出不同的分类器，然后用这些从不同角度训练出来的分类器对无标签样本进行分类，再选出认为可信的无标签样本加入训练集中。由于这些分类器从不同角度训练出来的，可以形成一种互补，而提高分类精度；就如同从不同角度可以更好地理解事物一样。

**半监督字典学习**：其实也是 self-training 的一种，先是用有标签数据作为字典，对无标签数据进行分类，挑选出你认为分类正确的无标签样本，加入字典中（此时的字典就变成了半监督字典了）

**标签传播算法**（Label Propagation Algorithm）：是一种基于图的半监督算法，通过构造图结构（数据点为顶点，点之间的相似性为边）来寻找**训练数据**中有标签数据和无标签数据的关系。是的，只是训练数据中，这是一种直推式的半监督算法，即只对训练集中的无标签数据进行分类，这其实感觉很像一个有监督分类算法...，但其实并不是，因为其标签传播的过程，会流经无标签数据，即有些无标签数据的标签的信息，是从另一些无标签数据中流过来的，这就用到了无标签数据之间的联系

**半监督支持向量机**：监督支持向量机是利用了结构风险最小化来分类的，半监督支持向量机还用上了无标签数据的空间分布信息，即决策超平面应该与无标签数据的分布一致（应该经过无标签数据密度低的地方）（**这其实是一种假设**，不满足的话这种无标签数据的空间分布信息会误导决策超平面，导致性能比只用有标签数据时还差）

其实，半监督学习的方法大都建立在对数据的某种假设上，只有满足这些假设，半监督算法才能有性能的保证，这也是限制了半监督学习应用的一大障碍。

## 半监督深度学习

无标签数据预训练，有标签数据微调
初始化方式：无监督预训练，和伪有监督预训练

利用从网络得到的深度特征来做半监督算法

让网络 work in semi-supervised fashion
真正的半监督学习


## 参考

- [半监督深度学习小结](https://zhuanlan.zhihu.com/p/33196506)