---
title: 人在回路
github: https://github.com/rmunro/pytorch_active_learning
---

![](https://pic1.zhimg.com/80/v2-221a12c3ba61160e375098dafcefc5bc_720w.jpg)

目前的机器学习仍然是监督学习任务表现出色。机器的智能的显性也是由于模型训练上万次在大型数据集上。但是我们仍可以看出一个模型很容易针对新的数据集而产生毁灭性灾难。除非环境永远一成不变，否则很多情况的“假智能”很快就显性出来。如何让模型能够顺应变化的环境，可能“人在回路”就是一种可行的解决办法。它主要依靠人的智能帮助机器更加智能化。而且这种混合智能已经成为热点。

> Annotation and Active Learning are the cornerstones of Human-in-the-Loop Machine Learning.

而这种标注或者主动学习，并不是让人把所有未见数据的标签全部标注，而是采取以一种采样的形式将有代表性或有迷惑性（对于二分类问题，模型只有 50% 左右的把握做出决策）的样本进行标注然后反馈给模型，模型则根据反馈调整模型，通过不断迭代，模型从而变得更佳鲁棒。此处作者又引入了迁移学习模型。

## 1 概述

AI 的“智能”不仅来源于训练数据，还包括人类的反馈。所以一个重要的问题是人和机器学习算法彼此交互来解决问题的正确方式是什么。**标注和主动学习**是人在环路机器学习的基石,它们决定了如何获取训练数据，以及当没有足够的预算或时间对所有数据进行人工标注时，将哪些数据正确地放在标注者面前是更合适。*迁移学习*使我们能够避免*冷启动*，使现有的机器学习模型快速适应新任务。

### 1.1 人在回路基本原理

人在回路的机器学习是人和机器学习过程进行交互，来解决以下的问题：

- 使 ML 更准确
- 使 ML 更快达到所需的准确度
- 使人类更准确
- 使人类更高效

### 1.2 标注

Annotation 就是人工标注。标注工作对模型的好坏也有着非常大的影响，甚至和模型本身一样重要。

在学术界，我们倾向于保持数据集不变，因为这样便于比较出各种算法孰优孰劣。但是在工业界，数据集总是在变化。一是因为不断增加标注数据对于提高模型性能还是很重要的，二是实际环境下数据的性质会随着时间的推移而产生变化，在新生产生活中用到的模型需要不断学习和适应新的数据环境。

标注还有一个常见的问题就是人工错误带来的噪声。随机的噪声可能会帮助算法避免过拟合，进而更加准确和鲁棒，但是人类的错误往往都是有一定倾向性、主观性的，就会给数据引入不可恢复的偏差。.

### 1.3 Introducing Active Learning: improving the speed and reducing the cost of training data

有三种基本的主动学习策略：不确定性采样（Uncertainty Sampling）、多样性采样（Diversity Sampling）和随机采样（Random Sampling）。一些文献中会将不确定性采样和多样性采样称为“Exploitation”和“Exploration”

Random Sampling 就是随机采样。这种一般都用在标注初期。

Uncertainty Sampling 是指对在模型的**决策边界的未标注样本**进行采样。因为这些样本是当前模型非常难以确定的，极容易被标注错误的。所以先对这些样本进行标注可以帮助更好的确定决策边界。

Diversity Sampling是指对一些不常见的或者其特征从未见过的样本进行采样。这种策略可以让模型对数据空间有更完整的理解。因此也有些文献将多样性采样称为异常值检测/异常检测“Outlier Detection” and “Anomaly Detection”。还有一种多样性采样是代表性样本采样，找到最典型的、最符合标签的样本。

一般来说，这些策略都会混合使用。而且主动学习是一个迭代的过程，新标注的样本加入训练数据后，模型会重新训练，然后再根据新模型进行下一轮样本挑选。迭代的次数和每次迭代需要新标注的样本数是视具体任务而定的。

### 1.4 Machine Learning and Human-Computer Interaction

- 交互界面的重要性
- 什么会影响人类的感知？
- 通过评估 ML 的预测来创建标签

### 1.5 Machine Learning-Assisted Human vs Human-Assisted Machine Learning

- 机器翻译
- 搜索引擎

### 1.6 Transfer learning to kick-start your models

迁移学习/预训练模型帮助你不用从头开始训练你的模型。

### 1.7 What to expect in this text

作者提出了四个象限：

- Known Knowns: what your Machine Learning model can confidently and accurately do today. This is your model in its current state.
- Known Unknowns: what your Machine Learning model cannot confidently do today. You can apply Uncertainty Sampling to these items.
- Unknown Knowns: knowledge within pre-trained models that can be adapted to your task. Transfer learning allows you to use this knowledge.
- Unknown Unknowns: gaps in your Machine Learning model where it is blind today. You can apply Diversity Sampling to these items.

![](https://img-blog.csdnimg.cn/img_convert/7c4c538a81ab4c38823dd8610fab85c0.png)

---

Hack-tive learning 就是 Active learning，就是作者与同事交流时，由于口音产生的梗。

主动学习真实世界的数据到机器学习数据的映射。

用来做研究的公开数据集很可能经过了手工规则筛选和采样，并不能完全代表真实世界的数据。

### Links

- [人在回路（Human in the loop)学习中...](https://zhuanlan.zhihu.com/p/343074171)
- [human-in-the-loop 机器学习简介](https://zhuanlan.zhihu.com/p/407340610)