---
title: 多标签分类
---

- [将“softmax+交叉熵”推广到多标签分类问题](https://kexue.fm/archives/7359)

#### 意义

网络新闻往往含有丰富的语义，一篇文章既可以属于“经济”也可以属于“文化”。给网络新闻打多标签可以更好地反应文章的真实意义，方便日后的分类和使用。

#### 难点

1. 类标数量不确定，有些样本可能只有一个类标，有些样本的类标可能高达几十甚至上百个。 

2. 类标之间相互依赖，例如包含蓝天类标的样本很大概率上包含白云，如何解决类标之间的依赖性问题也是一大难点。

3. 多标签的训练集比较难以获取。

Multi-Label 和传统的分类问题的区别主要在于多 Label 下，输出空间呈现指数级增长。那么目前对于 Multi-Label 的这类特性，**学界一般是集中在更好的分析 Label 之间的相关性，就可以避免这种指数增长**。

主要的 Strategy 大致可以分为三类：

- First-Order Strategy: 考虑的是 label 之间相互独立，那么就可以把 Multi-label 问题转换为普通的分类问题。如果一个 Label 有多类的话，那么就用传统的 One vs All 来解决。
- Second-Order Strategy: 这一类是考虑 Labe l之间的两两相关性，结果会导致计算复杂度有显著的增加。
- High-Order Strategy: 这个就是考虑多 Label 之间的相关性，计算复杂度会更高。

目前有的一些分类算法

- Binary Relevance，如名字所写，这是一个 First-Order Strategy
- Classifier Chains，把原问题分解成有先后顺序的一系列 Binary Classification，然后前边的 Binary Classification 会对后边的产生影响
- Calibrated label ranking，这个有点像 Multi-Classification 中 One vs One 的策略，就是通过两两对比，然后进行投票决定分类效果。

#### 方法

目前有很多关于多标签的学习算法，依据解决问题的角度，这些算法可以分为两大类

1. 基于问题转化的方法
2. 基于算法适用的方法
   - 修改现有的单标签分类算法以适应解决多标签分类问题
     - 修改后决策树最后每一个叶子都将对应一个标签组合
     - 修改 SVM 或者神经网络等，对每个标签得到的值进行排序，然后通过最小化 ranking loss 进行学习

#### Extreme Multi-Label Learning (XML)

在文本分类，推荐系统，Wikipedia，Amazon 关键词匹配等等应用中，我们通常需要从非常巨大的标签空间中召回标签。比如，很多人会 po 自己的自拍到 FB、Ins 上，我们可能希望由此训练一个分类器，自动识别谁出现在了某张图片中。

对 XML 来说，首要的问题就是标签空间、特征空间都可能非常巨大，例如 Manik Varma 大佬的主页中给出的一些数据集，标签空间的维度甚至远高于特征维度。其次，由于如此巨大的标签空间，可能存在较多的 Missing  Label（下文会进一步阐述）。最后，标签存在长尾分布，绝大部分标签仅仅有少量样本关联。

现有的 XML 方法大致可以分为三类，分别为

- Embedding Methods
- Tree-Based Methods
- One-vs-All Methods

近年来，也有很多文献使用了深度学习技术解决 XML 问题。

XML 的研究热潮大概从 2014 年开始，Varma 大佬搭建了 XML 的 Repository 后，已经有越来越多的研究者开始关注，多年来 XML 相关的文章理论和实验结果并重，值得更多的关注。

#### Multi-Label with Limited Supervision

相比于传统学习问题，对多标签数据的**标注十分困难**，更大的标签空间带来的是**更高的标注成本**。随着我们面对的问题越来越复杂，样本维度、数据量、标签维度都会影响标注的成本。因此，**近年多标签的另一个趋势是开始关注如何在有限的监督下构建更好的学习模型**。本文将这些相关的领域主要分为三类：

MLC with Missing Labels（MLML）：多标签问题中，标签很可能是缺失的。例如，对 XML  问题来说，标注者根本不可能遍历所有的标签，因此标注者通常只会给出一个子集，而不是给出所有的监督信息。文献中解决该问题的技术主要有基于图的方法、基于标签空间（或 Latent 标签空间）Low-Rank 的方法、基于概率图模型的方法。

Semi-Supervised MLC：MLML 考虑的是标签维度的难度，但是我们知道从深度学习需要更多的数据，在样本量上，多标签学习有着和传统 AI 相同的困难。半监督 MLC 的研究开展较早，主要技术和 MLML 也相对接近，在这一节，我们首先简要回顾了近年半监督 MLC 的一些最新工作。

但是，近年来，半监督 MLC 开始有了新的挑战，不少文章开始结合半监督 MLC 和 MLML 问题。毕竟对于多标签数据量来说，即使标注少量的 Full  Supervised 数据，也是不可接受的。因此，许多文章开始研究一类弱监督多标签问题 [4]（Weakly-Supervised  MLC，狭义），也就是数据集中可能混杂 Full labeled/missing labels/unlabeled  data。我们也在文中重点介绍了现有的一些 WS-MLC 的工作。

Partial Multi-Label Learning  (PML)：PML 是近年来多标签最新的方向，它考虑的是一类 “难以标注的问题”。比如，在我们标注下方的图片（Zhang et. al.  2020[5]）的时候，诸如 Tree、Lavender  这些标签相对是比较简单的。但是有些标签到底有没有，是比较难以确定的，对于某些标注者，可能出现：“这张图片看起来是在法国拍的，好像也可能是意大利？”。这种情况称之为 Ambiguous。究其原因，一是有些物体确实难以辨识，第二可能是标注者不够专业（这种多标签的情况，标注者不太熟悉一些事物也很正常）。

但是，很多情况下，标注者是大概能够猜到正确标签的范围，比如这张风景图所在国家，很可能就是 France 或者 Italy  中的一个。我们在不确定的情况下，可以选择不标注、或者随机标注。但是不标注意味着我们丢失了所有信息，随机标注意味着可能带来噪声，对学习的影响更大。所以 PML 选择的是让标注者提供所有可能的标签，当然加了一个较强的假设：所有的标签都应该被包含在候选标签集中。

在 Survey  中，我们将现有的 PML 方法划分为 Two-Stage Disambiguation 和 End-to-End 方法（我们 IJCAI  2019 的论文 DRAMA[6] 中，就使用了前者）。关于 PML 的更多探讨，我在之前的知乎回答里面也已经叙述过，大家也可以在我们的  Survey 中了解更多。

## 参考

- [最新综述：多标签学习的新趋势](https://www.jiqizhixin.com/articles/2020-12-14-2)
