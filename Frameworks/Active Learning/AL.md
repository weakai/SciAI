# 主动学习

## 0 基础

## 1 介绍

### 1.1 主动学习

主动学习是一种通过主动选择最有价值的样本进行标注的机器学习或人工智能方法。其目的是使用尽可能少的、高质量的样本标注使模型达到尽可能好的性能。也就是说，主动学习方法能够提高样本及标注的增益，在有限标注预算的前提下，最大化模型的性能，是一种从样本的角度，提高数据效率的方案，因而被应用在标注成本高、标注难度大等任务中，例如医疗图像、无人驾驶、异常检测、基于互联网大数据的相关问题。
![](https://tva1.sinaimg.cn/large/006C3FgEgy1gyc1qut5lwj30k00bmmye.jpg)

### 1.2 原理和思路

通过机器学习的方法获取到那些比较“难”分类的样本数据，让人工再次确认和审核，然后将人工标注得到的数据再次使用有监督学习模型或者半监督学习模型进行训练，逐步提升模型的效果，将人工经验融入机器学习的模型中。

在主动学习中，有三种典型场景。知名度最高的一种场景称为基于池的采样（Pool-based Sampling），它遵循以下五个步骤：
1. 人员（在此过程中称为 Oracle）标注数据集的一小部分，并将标注数据提供给模型。
2. 模型（称为主动学习者）处理这些数据，并以一定的置信度预测未标注数据点的类别。
3. 假设初始预测低于所需精度和置信度，则会使用采样技术确定下一个需要标注的数据子集。
4. 人员标注选定的数据子集并将标注的数据子集发送回模型进行处理。
5. 该过程将继续，直至模型的预测达到所需的置信度和精度水平。

![al](https://cdn.jsdelivr.net/gh/xxzhai123/img/img776dab0021964e148edbb2a6c4b8dbee~tplv-k3u1fbpfcp-zoom-in-crop-mark 1304 0 0 0.awebp.webp)

另一个主动学习场景即基于流的选择采样（Stream-based Selective Sampling）。

### 1.3 主动学习的分类

根据应用场景，主动学习的方法可以被分为 membership query synthesis，stream-based and pool-based三种类型。其中，pool-based 是最常见的场景，并且由于深度学习基于 batch 训练的机制，使得 pool-based 的方法更容易与其契合。

#### 1.3.1 根据输入数据的方式

- 基于流的主动学习，它将未标记的数据一次性全部呈现给一个预测模型，该模型将预测结果（实例的概率值），
  根据某些评价指标（比如margin）计算评估实例的价值，随后应用主动学习决定是否应该花费一些预算来收集此数据的类标签，以进行后续的训练；

- 基于池的主动学习，这个通常是离线、反复的过程。
  这里向主动学习系统提供了大量未标记的数据，在此过程的每个迭代周期，主动学习系统都会选择一个或者多个未标记数据进行标记并用于随后的模型训练， 直到预算用尽或者满足某些停止条件为止。
  此时，如果预测性能足够，就可以将模型合并到最终系统中，该最终系统为模型提供未标记的数据并进行预测。

#### 1.3.2 根据数据选择的角度

- 仅基于独立同分布（IID）数据的不确定性进行主动学习，其中选择标准仅取决于针对每个数据自身信息计算的不确定性值；

- 通过进一步考虑实例相关性来进行主动学习，基于数据相关性的不确定性度量标准，利用一些相似性度量来区分数据之间的差异。

基于不确定性的方法
基于信息量的策略由于实用性强，因此被广泛使用。
不确定性越大，蕴含的信息量越大，越有训练价值。
用已打标的数据子集训练模型，用该模型预测剩余未打标样本，根据预测结果使用不确定性衡量标准找出最不确定的样本，交给打标人员标注，加入训练集训练模型，再用该模型进行数据挑选，反复迭代。
代表方法

1. least confident(LC): 关注模型预测时置信度值很大，“可信度”依旧很低的样本。缺点是没关注易混淆的样本。
2. smallest margin（SM）:关注置信度最大的两个值的差（margin）最小的样本，即易混淆的样本，该方案是针对LC的缺点进行的改进。
3. entropy（ENT）: 关注综合信息量最大的样本。

基于委员会查询的方法（Query-By-Committee，QBC）
将优化 ML 模型看成是版本空间搜索，QBC 通过压缩版本空间的搜索范围，找到最优秀ML模型。
相同训练集训练多个同结构的模型，模型投票选出争议样本，将争议样本打标后训练模型，反复迭代。

### 1.3 基本查询策略

在主动学习框架中，最重要的就是如何设计一个查询策略来判断样本的价值，即是否值得被 oracle 标注。而样本的价值并不是一成不变的，它不仅与样本自身有关，还和任务和模型等因素有关。一个简单的例子，在猫狗二分类问题中，一张长得像猫的狗的照片，对分类模型的训练往往是有价值，因为它难以分辨。但是，同样是这张照片，出现在动植物二分类问题中，就变得不那么重要了，因为模型想分辨它并不难。因此，查询策略的设计并不是简单和一成不变的，需要根据具体环境、问题和需要进行设定。这样就产生了各种各样的查询策略，下面，我介绍一些基本的查询策略供大家参考。

#### 1.3.1 不确定性采样

- **最简单直接也最常用的策略** 算法只需要查询最不确定的样本给 oracle 标注。
- 例如，刷错题本和重难题本。
- 方法和手段举例
  - 基于概率的神经网络，可以直接利用概率来表示不确定性。比如，直接用概率值，概率值排名第一和第二的差值，熵值等等。

#### 1.3.2 多样性采样

- **从数据的分布考虑** 算法根据数据分布确保查询的样本能够覆盖整个数据分布以保证标注数据的多样性。例如，老师在出考试题的时候，会尽可能得出一些有代表性的题，同时尽可能保证每个章节都覆盖到，这样才能保证题目的多样性全面地考察学生的综合水平。

- **多样性采样方法**：

  - 基于模型的离群值
    - 指标: 词频, 编辑距离, tf-idf

  - 代表性采样: 选择一些最有代表性的样本，例如采用聚类等簇的方法获得代表性样本和根据不同域的差异找到代表性样本

  - 真实场景多样性: 根据真实场景的多样性和样本分布，公平地采样。

**预期模型改变(Expected Model Change)** ：EMC通常选择对当前模型改变最大、影响最大的样本给oracle标注，一般来说，需要根据样本的标签才能反向传播计算模型的改变量或梯度等。在实际应用中，为了弱化需要标签这个前提，一般根据模型的预测结果作为伪标签然后再计算预期模型改变。当然，这种做法存在一定的问题，伪标签和真实标签并不总是一致的，他与模型的预测性能有关。

**委员会查询 (Query-By-Committee)**：QBC是利用多个模型组成的委员会对候选的数据进行投票，即分别作出决策，最终他们选择最有分歧的样本作为最有信息的数据给oracle标注。

此外，有些研究者将多种查询策略结合起来使用混合策略进行查询，例如即考虑不确定性又考虑多样性的。还有一些其他的查询策略，例如预期误差减少、方差减少、密度加权法等。

### 1.4 经典方法

**Entropy** 可直接根据预测的概率分布计算熵值，选择熵值最大的样本来标注。

**BALD** Deep Bayesian Active Learning with Image Data

**BGADL** Bayesian Generative Active Deep Learning

**Core-set** Active Learning for Convolutional Neural Networks: A Core-Set Approach

**LLAL** Learning Loss for Active Learning

**VAAL** Variational Adversarial Active Learning

## Links

- [Learning with not Enough Data Part 2: Active Learning | by Lilian Weng@OpenAI ](https://lilianweng.github.io/posts/2022-02-20-active-learning/)
- [主动学习方法实践：让模型变“主动”](https://developer.aliyun.com/article/766940)
- [主动学习(Active Learning)介绍](https://www.jianshu.com/p/e908c3595fc0)
- [主动学习](https://lccurious.github.io/2019/08/27/Active-Learning/)
- [[Active Learning] 01 主动学习简介](https://www.cnblogs.com/wuliytTaotao/p/10758963.html)
- [主动学习（Active Learning）概述及最新研究](https://www.cvmart.net/community/detail/6018)