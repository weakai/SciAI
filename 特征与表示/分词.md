# 分词

现在的分词方法大概可以分为三个类别：基于字符串匹配的分词方法、基于统计的分词方法和基于理解的分词方法。

## 基于字符串匹配的分词方法 基于词典的方法

机械分词方法，它是按照一定的扫描方式将待分词的句子中的词条与语料库中的词进行匹配，然后返回相应的结果。这种匹配的算法按照扫描的方式又可以分成

1. 正向最大匹配法（由左到右的方向）
2. 逆向最大匹配法（由右到左的方向)
3. 最少切分（使每一句中切出的词数最小, 可以使用动态规划的思想，划分成局部问题)
4. 双向最大匹配法（进行由左到右、由右到左两次扫描）

## 基于统计的分词方法

基于统计的分词方法是在给定大量已经分词的文本的前提下，利用统计机器学习模型学习词语切分的规律（称为训练），从而实现对未知文本的切分。
例如最大概率分词方法和最大熵分词方法等。

N 元文法模型（N-gram）
隐马尔可夫模型（Hidden Markov Model ，HMM）
最大熵模型（ME）
条件随机场模型（Conditional Random Fields，CRF）等。
这样的方法一般分为两个步骤：
1. 找出句子的所有分词结果
2. 在所有的分词结果中找到最好的那一个

得到了所有的分词结果以后，我们需要判断哪一种分词结果最好，那么分词结果的好坏可以用语言模型来确定，具体的模型有unigram，bigram等，一般不会超过trigram。
假定我们用 unigram 这个模型，并且知道每个单词在词库中的权重（或者称之为概率，通常以出现的频率来衡量），
那么每个分词结果的得分值可以用该分词结果的每个词概率的乘积来衡量。

## 基于理解的分词方法

基于理解的分词方法是通过让计算机模拟人对句子的理解，达到识别词的效果。
其基本思想就是在分词的同时进行句法、语义分析，利用句法信息和语义信息来处理歧义现象。

## Links

- [NLP 中常用的分词方法和实现](https://zhuanlan.zhihu.com/p/65190736)