# 表示学习

数据决定了机器学习的上限，而算法只是尽可能逼近这个上限。
这里的数据指的就是经过特征工程得到的数据。
特征工程就是一个把原始数据转变成特征的过程，这些特征可以很好的描述这些数据，并且利用它们建立的模型在未知数据上的表现性能可以达到最优（或者接近最佳性能）。
从数学的角度来看，特征工程就是去设计输入变量 X。

首先给出表示学习的定义：

为了提高机器学习系统的准确率，我们就需要将输入信息转换为有效的特征，或者更一般性称为表示（Representation）。
如果有一种算法可以自动地学习出有效的特征，并提高最终机器学习模型的性能，那么这种学习就是可以叫做表示学习（Representation Learning）。

表示学习的关键是解决**语义鸿沟（Semantic Gap）**问题。
语义鸿沟问题是指输入数据的底层特征和高层语义信息之间的不一致性和差异性。
比如给定一些关于“车”的图片，由于图片中每辆车的颜色和形状等属性都不尽相同，不同图片在像素级别上的表示（即底层特征）差异性也会非常大。
但是我们人理解这些图片是建立在比较抽象的高层语义概念上的。
如果一个预测模型直接建立在底层特征之上，会导致对预测模型的能力要求过高。
如果可以有一个好的表示在某种程度上可以反映出数据的高层语义特征，那么我们就可以相对容易地构建后续的机器学习模型。

在表示学习中，有两个核心问题：一是“什么是一个好的表示？”；二是“如何学习到好的表示？”

好的表示没有明确的标准，但通常具有以下几个优点：

- 一个好的表示应该具有很强的表示能力，即同样大小的向量可以表示更多信息。
- 一个好的表示应该使后续的学习任务变得简单，即需要包含更高层的语义信息。
- 一个好的表示应该具有一般性，是任务或领域独立的。虽然目前的大部分表示学习方法还基于某个任务来学习，但我们期望学到的表示可以比较容易迁移到其它任务上。

在传统机器学习中，我们经常使用两种方式来表示特征：局部表示（Local Representation）和分布式表示（Distributed Representation）。
以颜色表示为例，一种表示颜色的方法是以不同名字来命名不同的颜色，这种表示方式叫做 one-hot 局部表示，也称为离散表示或符号表示。
局部表示通常可以表示为向量的形式。

局部表示有两个不足之处：
1. one-hot 向量的维数很高，且不能扩展。 如果有一种新的颜色，我们就需要增加一维来表示； 
2. 不同颜色之间的相似度都为 0，即我们无法知道“红色”和“中国红”的相似度要比“红色”和“黑色”的相似度要高。

另一种表示颜色的方法是用 RGB 值来表示颜色，不同颜色对应 R、G、B 三维空间中一个点，这种表示方式叫做分布式表示。
分布式表示通常可以表示为低维的稠密向量。
和局部表示相比，分布式表示的表示能力要比局部表示强很多，分布式表示的向量维度一般都比较低。
我们只需要用一个三维的稠密向量就可以表示所有颜色。
并且分布式表示也很容易表示新的颜色名。
此外，不同颜色之间的相似度也很容易计算。

我们可以使用神经网络来将高维的局部表示空间 $\mathbb{R}^{|\nu|}$ 映射到一个非常低维的分布式表示空间 $\mathbb{R}^{d}$。
在这个低维空间中，每个特征不再是坐标轴上的点，而是分散在整个低维空间中。

在机器学习中，这个过程也称为嵌入（Embedding）。
嵌入通常指将一个度量空间中的一些对象映射到另一个低维的度量空间中，并尽可能保持不同对象之间的**拓扑关系**。
比如自然语言中词的分布式表示，也经常叫做词嵌入。

要学习到一种好的高层语义表示（一般为分布式表示），通常需要从底层特征开始，经过多步非线性转换才能得到。
一个深层结构的优点是可以增加特征的连续多次的线性转换等价于重用性，**从而指数级地增加表示能力**。
因此，表示学习的关键是**构建具有一定深度的多层次特征表示**。

传统的特征学习一般是通过人为地设计一些准则，然后根据这些准则来选取有效的特征。
特征的学习是和最终预测模型的学习分开进行的，因此学习到的特征不一定可以提升最终模型的性能。

## 深度学习

为了学习一种好的表示，需要构建具有一定“深度”的模型，并通过学习算法来让模型自动学习出好的特征表示（从底层特征，到中层特征，再到高层特征），
从而最终提升预测模型的准确率。
所谓“深度”是指原始数据进行非线性特征转换的次数。
如果把一个表示学习系统看作是一个有向图结构，深度也可以看作是从输入节点到输出节点所经过的最长路径的长度。

深度学习与表示学习关系如下：

![](https://cdn.jsdelivr.net/gh/xxzhai123/img/img2022-05-27_20-06.png)

和“浅层学习”不同，深度学习需要解决的关键问题是**贡献度分配问题**，即一个系统中不同的组件或其参数对最终系统输出结果的贡献或影响。
以下围棋为例，每当下完一盘棋，最后的结果要么赢要么输。
我们会思考哪几步棋导致了最后的胜利，而又是哪几步棋导致了最后的败局。
如何判断每一步棋的贡献就是贡献度分配问题，这也是一个非常困难的问题。
从某种意义上讲，深度学习也可以看作是一种强化学习（Reinforcement Learning，RL），
每个内部组件并不能直接得到监督信息，需要通过整个模型的最终监督信息（奖励）得到，并且有一定的延时性。
目前，深度学习采用的模型主要是神经网络模型，其主要原因是神经网络模型可以使用误差反向传播算法，从而可以比较好地解决贡献度分配问题。

在一些复杂任务中，传统机器学习方法需要将一个任务的输入和输出之间人为地切割成很多子模块（或多个阶段），每个子模块分开学习。
比如一个自然语言理解任务，一般需要分词、词性标注、句法分析、语义分析、语义推理等步骤。
这种学习方式有两个问题：一是每一个模块都需要单独优化，并且其优化目标和任务总体目标并不能保证一致。
二是错误传播，即前一步的错误会对后续的模型造成很大的影响。这样就增加了机器学习方法在实际应用的难度。

端到端学习（End-to-End Learning），
也称端到端训练，是指在学习过程中不进行分模块或分阶段进行训练，直接优化任务的总体目标。
在端到端学习中，一般不需要明确地给出不同模块或阶段的功能，中间过程不需要人为干预。

## Links

- [表示学习与深度学习](https://www.jianshu.com/p/b1dcd8811326)
- [什么是表示学习(representation learning)表征学习 表达学习](https://blog.csdn.net/sinat_26811377/article/details/108335288)
- [表示学习(Representation Learning)](https://blog.csdn.net/weixin_40449300/article/details/89941348)

