---
title: t-SNE
subtitle: t-distributed Stochastic Neighbor Embedding
tags: [t-SNE, 降维]
---

t-SNE 是一种集降维与可视化于一体的技术，它是基于 SNE 可视化的改进，解决了SNE在可视化后样本分布拥挤、边界不明显的特点，是目前最好的降维可视化手段。

所谓的 t-SNE 算法，总结一下其实就是在 SNE 的基础上增加了两个改进：一是把 SNE 变为对称 SNE，二是在低维空间中采用了 t 分布代替原来的高斯分布，高维空间不变。

t-分布邻域嵌入算法，非线性降维方法（一般用于可视化），成功的应用于很多真实数据集。属于非监督学习，属于流形学习。

t-SNE 是深度学习大牛 Hinton 和 lvdmaaten 在2008年提出的。

t-SNE 将数据点的相似性转换为概率。原始空间中的相似度用高斯联合概率表示，嵌入空间中的相似度用学生 t 分布表示。t-SNE 算法包括两个主要阶段。先，t-SNE 在高维对象上构建概率分布，即相似的对象被选中的概率很高，而相异的对象被选中的概率非常小。然后，t-SNE 在低维映射中的点上定义了类似的概率分布，并且使两个分布之间的 KL 散度最小。 

## 使用场合

t-SNE 本身可以用于降维，但是主要被用于可视化，而且可视化效果非常好。

Kaggle 里有些人会把 t-SNE 降维后的数据当做 feature。  
 有人用 t-SNE 看 CNN 中全连接层的数据，发现相似的会聚在一起。  
t-SNE 不能算是一种通用的降维方法吧，时间复杂度也挺高的。
 **降维是手段，认识数据是目的。**

 ## t-SNE 的改进
 
就是各种树算法轮番上阵。

2014 年的时候，Maaten 又写了一篇论文对 t-SNE 算法进行了改进，使用了各种基于树的算法，具体包括两部分内容：一是采用了 kNN 图来表示高维空间中点的相似性；二是优化了梯度的求解过程，将梯度计算分为引力和斥力两部分，同样使用了一些优化技巧。

虽然 t-SNE 算法和它的改进算法都得到广泛应用，但存在两个不足：一是处理**大规模高维数据**时，t-SNE 的效率显著降低(包括改进后的算法)；二是 t-SNE 中的参数对不同数据集较为**敏感**，我们辛辛苦苦的在一个数据集上调好了参数，得到了一个不错的可视化效果，却发现不能在另一个数据集上适用，还得花费大量时间寻找合适的参数。

## 参考

[t-SNE 实践—— sklearn 教程](https://blog.csdn.net/hustqb/article/details/80628721)