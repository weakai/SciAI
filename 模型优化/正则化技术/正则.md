# 正则

机器学习的一个核心问题是设计不仅在训练数据上表现好，而且能在新输入上的泛化能力好的算法。在机器学习中，许多策略被显式的设计来减少测试误差。这些策略统称为正则化。

#### 参数范数惩罚

- 在神经网络中，我们通常只对权重做惩罚而不对偏置做惩罚。因为每个权重会指定两个变量如何作用，而偏置只会控制一个单变量，因而我们不对偏置进行正则化方差也不会特别大，此外对正则化偏置可能会导致明显的欠拟合。
- L^2权重衰减是权重衰减最常见的形式，我们还可以使用L ^1 正则化
- 与L2正则化相比，L1正则化会产生更稀疏解。
- 许多正则化策略可以被解释为MAP贝叶斯推断，特别是L2正则化相当于权重是高斯先验的MAP贝叶斯推断。

#### 为约束的范数惩罚



#### 提前终止

- 提前终止可能是深度学习中最常用的正则化形式。
- 提前终止是一种正则化策略。
- 提前终止可以将优化过程的参数空间限制在初始参数值 sita0 的小邻域内。

#### 数据集增强

