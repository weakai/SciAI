---
title: 特征工程
---

## 数据去噪

数据清洗
考虑哪些信息对于模型结果是有效的，去掉脏数据
补齐缺省值（中位数补齐、平均数补齐）

## 数据平衡

数据不平衡？
首先考虑真实世界本来就是不平衡的
如果是

1. 拷贝占比小的样本
2. 或，在损失函数中加权

## 列表转张量

数据向量化（一般是浮点张量）

### 填充列表

对应 交叉熵

### one-hot 编码

也叫分类编码

对应 二进制交叉熵

```python
# 标签向量化
from keras.utils.np_utils import to_categorical
one_hot_train_labels = to_categorical(train_labels)
one_hot_test_labels = to_categorical(test_labels)
```

## 特征标准化

如果很多特征的取值范围有很大的区别，尽管网络能够适应这种变化，但是会使得学习变的困难。

特征平均值为 0，标准差为 1。

**特点**

> 取值较小
> 同质性所有特征的取值都应该在大致相同的范围内

```python
mean = train_data.mean(axis=0)
train_data -= mean
std = train_data.std(asxis=0)
train_data /= std
# 谨记 用于测试数据标准化的均值和标准差都是在训练数据上计算得到的。
# 在工作流程中，你不能使用在测试数据上计算任何得到的结果。
test_data -= mean
test_data /= std
```

## 缺失值处理
对于神经网络，缺失值置 0 一般是安全的，只要 0 不是一个有意义的值

## 特征工程

本质
> 用更简单的方式表述问题，从而使问题变更容易

幸运的是，现代深度学习中，大部分特征工程都是不需要的。然而还需要注意：

> 1. 优雅地解决问题需要特征工程：使用卷积神经网络来读取钟面上的时间是很可笑的
> 2. 对于样本量少的信息，特征信息的价值巨大

## K 折交叉验证

在调节网络参数的同时对网络进行评估

使用场景：数据点很少，验证集会非常小会导致验证分数有很大波动，即各个验证分数的方差较大，因此无法有效地评估模型。

![K 折交叉验证](https://cdn.jsdelivr.net/gh/xxzhai123/img/imgIMG_20210707_164744.jpg)

### :+1:带有打乱数据的重复 K 折验证

计算代价大，训练的模型数多

## 简单的留出验证

![简单的留出验证](https://cdn.jsdelivr.net/gh/xxzhai123/img/img2021-07-08%2010-03-36%20%E7%9A%84%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE.png)
