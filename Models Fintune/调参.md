---
title: 炼丹术
subtitle: 调参
---

ML 工作流中最困难的部分之一是为模型找到最好的超参数。ML 模型的性能与超参数直接相关。调优超参数可能是非常乏味和困难的，更像是一门艺术而不是科学。

## 理论和实践

理论和实践之间的Gap往往差异巨大，学术 paper 更关注的是模型架构设计的新颖性等，更重要的是新的思路；
而实践最重要的是在落地场景的效果，关注的点和方法都不一样。这部分简单梳理实际做项目过程中的一点经验教训。

## 模型

模型显然并不是最重要的：不能否认，好的模型设计对拿到好结果的至关重要，也更是学术关注热点。但实际使用中，模型的工作量占的时间其实相对比较少。虽然再第二部分介绍了5种CNN/RNN及其变体的模型，实际中文本分类任务单纯用 CNN 已经足以取得很不错的结果了，我们的实验测试 RCNN 对准确率提升大约1%，并不是十分的显著。最佳实践是先用 TextCNN 模型把整体任务效果调试到最好，再尝试改进模型。

## 数据

理解你的数据：虽然应用深度学习有一个很大的优势是不再需要繁琐低效的人工特征工程，然而如果你只是把他当做一个黑盒，难免会经常怀疑人生。一定要理解你的数据，记住无论传统方法还是深度学习方法，数据 sense 始终非常重要。要重视 badcase 分析，明白你的数据是否适合，为什么对为什么错。

## 记录

关注迭代质量 - 记录和分析你的每次实验：迭代速度是决定算法项目成败的关键，学过概率的同学都很容易认同。而算法项目重要的不只是迭代速度，一定要关注迭代质量。如果你没有搭建一个快速实验分析的套路，迭代速度再快也只会替你公司心疼宝贵的计算资源。建议记录每次实验，实验分析至少回答这三个问题：为什么要实验？结论是什么？下一步怎么实验？

## 超参调节

### 提高速度

一般在小数据集上合适的参数，在大数据集上效果也不会太差。因此可以尝试对数据进行精简，以提高速度，在有限的时间内可以尝试更多参数。

- 对训练数据进行采样。例如原来 100W 条数据，先采样成 1W，进行实验看看。
- 减少训练类别。例如手写数字识别任务，原来是 10 个类别，那么我们可以先在 2 个类别上训练，看看结果如何。

### 由粗到细

1. 论文中的参数至少是一个不差的结果
2. 先从对实验影响较大的参数开始调
   1. 学习率
   2. 正则值，dropout 值

建议优先在对数尺度上进行超参数搜索。比较典型的是学习率和正则化项，我们可以从诸如0.001 0.01 0.1 1 10，以10为阶数进行尝试。因为他们对训练的影响是相乘的效果。不过有些参数，还是建议在原始尺度上进行搜索，例如dropout值: 0.3 0.5 0.7)。

### 经验参数

1. lr: 1 0.1 0.01 0.001。学习率一般要随着训练进行衰减。衰减系数一般是0.5。 衰减时机，可以是验证集准确率不再上升时，或固定训练多少个周期以后。建议使用自适应梯度的办法，例如 adam, adadelta, rmsprop等，这些一般使用相关论文提供的默认值即可，可以避免再费劲调节学习率。对 RNN 来说，有个经验，如果RNN要处理的序列比较长，或者RNN层数比较多，那么learning rate一般小一些比较好，否则有可能出现结果不收敛，甚至Nan等问题。
2. 网络层数： 先从1层开始
3. 每层结点数：16 32 128 超过1000的情况比较少见。超过1W的从来没有见过
4. batch size: 128上下开始。batch size值增加，的确能提高训练速度。但是有可能收敛结果变差。如果显存大小允许，可以考虑从一个比较大的值开始尝试。因为 batch size 太大，一般不会对结果有太大的影响，而 batch size 太小的话，结果有可能很差。
5. clip c(梯度裁剪)：限制最大梯度,其实是value = sqrt(w1^2+w2^2….),如果value超过了阈值，就算一个衰减系系数,让value的值等于阈值: 5,10,15
6. dropout： 0.5
7. L2正则：1.0，超过10的很少见
8. 词向量embedding大小：128，256
9. 正负样本比例：重要但被忽视。除了尝试训练数据默认的正负类别比例之外，建议对数目较小的样本做过采样，例如进行复制。提高他们的比例，看看效果如何，这个对多分类问题同样适用。在使用mini-batch方法进行训练的时候，尽量让一个batch内，各类别的比例平衡，这个在图像识别等多分类任务上非常重要。

### 自动调参

1. Grid Search。优点是实现简单暴力，如果能全部遍历的话，结果比较可靠。缺点是太费时间了，特别像神经网络，一般尝试不了太多的参数组合。
2. Random Search。Bengio 已经证明 Random Search 比 Gird Search 更有效。实际操作的时候，一般也是先用Gird Search的方法，得到所有候选参数，然后每次从中随机选择进行训练。
3. Bayesian Optimization。贝叶斯优化。考虑到了不同参数对应的实验结果值，因此更节省时间。考虑到了不同参数对应的实验结果值，因此更节省时间。和网络搜索相比简直就是老牛和跑车的区别。

### 实验参数

由于深度学习实验超参众多，代码风格良好的实验环境，可以让你的人工或者自动调参更加省力，有以下几点可能需要注意：

1. 将各个参数的设置部分集中在一起。如果参数的设置分布在代码的各个地方，那么修改的过程想必会非常痛苦。将常用的重要的参数往前移动。
2. 可以输出模型的损失函数值以及训练集和验证集上的准确率。
3. 可以考虑设计一个子程序，可以根据给定的参数，启动训练并监控和周期性保存评估结果。再由一个主程序，分配参数以及并行启动一系列子程序。

## 可视化

画图是一个很好的习惯，一般是训练数据遍历一轮以后，就输出一下训练集和验证集准确率。同时画到一张图上。这样训练一段时间以后，如果模型一直没有收敛，那么就可以停止训练，尝试其他参数了，以节省时间。

## 参考

- [深度学习模型训练全流程！](https://blog.csdn.net/abcdefg90876/article/details/106700361)
- [用深度学习（CNN RNN Attention）解决大规模文本分类问题 - 综述和实践](https://zhuanlan.zhihu.com/p/25928551)
