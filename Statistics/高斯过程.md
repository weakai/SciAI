# 高斯过程

首先简单理解高斯过程，比如你有 t=T 个时间点，每个时间点的观测值都是高斯分布的，并且任意 k 个时间点的观测值的组合都是联合高斯分布。
这样的一个过程称为高斯过程。

高斯过程通常可以用来表示一个函数，更具体来说是表示一个函数的分布（先不急着理解这句话，看到最后就明白了）。
通常如果我们要学习一个函数（或者说学习一个映射），首先定义函数的参数，然后根据训练数据来学习这个函数的参数。
例如我们做线性回归，学习这样一个函数就相当于训练回归参数（权重、偏置）。
这种方法叫做参数化的方法。
但是这种做法就把可学习的函数的范围限制死了，无法学习任意类型的函数。
而非参数化的方法就没有这个缺点。
用高斯过程来建模函数，就是一种非参数方法。

## 概率神经网络

- [概率神经网络（PNN）](https://www.geek-share.com/detail/2798944232.html)

## Links

- [Gaussian Processes | 强烈推荐](https://borgwang.github.io/ml/2019/07/28/gaussian-processes.html)
- [通俗理解高斯过程及其应用](https://zhuanlan.zhihu.com/p/73832253)
