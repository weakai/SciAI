---
title: 强化学习是针对优化数据的监督学习
date: 2022-07-25
tags: [强化学习是针对优化数据的监督学习]
---

强化学习（RL）可以从两个不同的视角来看待：优化和动态规划。其中，诸如 REINFORCE 等通过计算不可微目标期望函数的梯度进行优化的算法被归类为优化视角，而时序差分学习（TD-Learning）或 Q-Learning 等则是动态规划类算法。

虽然这些方法在近年来取得了很大的成功，但依然不能很好地迁移到新任务上。相较于这些强化学习方法，深度监督学习能够很好的在不同任务之间进行迁移学习，因此我们不禁问：是否能将监督学习方法用在强化学习任务上？

在这篇博文中，我们讨论一种理论上的强化学习模型。首先我们认为强化学习可以看作是高质量数据上的监督学习，在此基础上，获取高质量数据（好数据）本身也具有挑战性（除非是模仿学习），因此强化学习可以进一步看作是针对策略和数据的联合优化问题。

从监督学习的角度来看，许多强化学习算法可以被认为是在交替地寻找更好数据 和 对数据进行监督学习。那么如何更有效地获取更好地数据呢？事实证明在多任务环境下，或者在多个问题可以相互转换的条件下更容易获取优质数据。因此，我们主要讨论如何从数据优化的角度来理解诸如hindsight relabeling数据增强法和inverse RL等技术。

接下来我们将首先回顾强化学习的两个主要研究视角，即优化和动态规划，然后将从有监督视角深入探讨强化学习。

## Reference

- [为什么说强化学习是针对优化数据的监督学习？](https://cloud.tencent.com/developer/article/1791851)