# Learning Records

## Finished

### 2022

- [ ] Life: 跑步 71 * 400m

#### August

#### July

- [x] Projects: Contrastive learning
  - [x] Learn: SimCSE
    - [x] Learn: SBERT
    - [x] what is dropout and dropout mask
    - [x] rough | learn BERT-flow
    - [x] Learn: Bert-white
      - [x] whitening
    - [x] Learn: ESimCSE
  - [x] Learn: SimCLR
    - [x] Survey on SimCLR: 
    - [x] Pytorch Lightning Tutorial 13
  - [x] Learn: Barlow Twins
    - [x] Survey on Barlow Twins
    - [x] Pytorch Lightning Tutorial: Barlow Twins
  - [x] Learn: Contrastive Active Learning (CAL)@give-up
    - [x] [contrastive-active-learning@Hard](https://github.com/mourga/contrastive-active-learning)
    - [x] [ALPS | Cold-start Active Learning through Self-supervised Language Modeling](https://arxiv.org/abs/2010.09535)
  - [x] Learn: SimCLR | Google | CV@Skip
- [x] Surveys on SSL
- [x] Bayes Nets: Probabilistic Graphical Models
- [x] 权重分布可视化
- [x] Learn: 清空待办事项
- [x] Documentation of Torch Drug
- [x] Practice: Write a custom bert
- [x] one page GitHub
- [x] Shell: EXA
- [x] A survey of 辅助学习
- [x] 条件随机场 + LSTM
- [x] A survey of 度量学习
- [x] 西瓜书 第二遍
- [x] Projects: Peptide GMT
  - [x] Check the representations@OK
  - [x] Experiments: Peptide GMT
    - [x] Figure out out-of-memory@Qiao sir
    - [x] without info of HLA
    - [x] with info of HLA
    - [x] hyper-tune without info of HLA
  - [x] Experiments: Peptide SMILES Transformer
    - [x] Python: 并发
    - [x] Only Peptide
      - [x] Build transformer
      - [x] Peptide SMILES Transformer Small Data
    - [x] With HLA
- [x] Learn Bert
  - [x] Huggingface + Pytorch lightning@faied 封装太严重了
- [x] 超大数据集的载入
- [x] [Bilibili University | 数学天才 陶哲轩Terence Tao 不再恐惧数学 学会新思维](https://www.bilibili.com/medialist/play/watchlater/BV1wa41187Wf)
- [x] 电视剧: 梦华录
- [x] A Survey of MTL
- [x] Learn@brief: Lightning-Bolt
  - [x] Learn: [Annotated Transformer](https://github.com/zhaisilong/annotated-transformer) 一行代码一行代码读，推敲公式，感觉学到了很多。花了近两天时间值不值得？
- [x] Known: PyMol
- [x] Project: 研习模型
  - [x] bert4pytoch@代码不行
  - [x] [pytorchic-bert](https://github.com/zhaisilong/pytorchic-bert)
  - [x] [Torch-Light: 各类模型经典代码]()
- [x] Learn: 动态学习率
  - [x] [Transformers 之自定义学习率动态调整](http://mp.weixin.qq.com/s?__biz=MzAwNjU0NjA3Ng==&mid=2247493007&idx=1&sn=a7d10c4de9e0f7562145f679d8da9582&chksm=9b09127cac7e9b6a9923111bafb87cd1d3ebf7b7c0b8adcd2c745affbd9e8cdd558ba12f5a9d&mpshare=1&scene=1&srcid=0621ufsUrQcky5OqBodaj4Ew&sharer_sharetime=1655769650495&sharer_shareid=f66ef27ade3d509229b2afd8611df712#rd)
- [x] Projects: Server
  - [x] docker with pytoch for DL
  - [x] re-learn docker

#### June

- [x] Learn: hdf5
- [x] Xu Jiangcheng
  - [x] To Author
  - [x] TMAP
- [x] Tidy my notebook workplace


#### May

- [x] Translation a review
- [x] 1 小时科普: 量子力学 | 朱梓忠 | 清华大学出版社
- [x] 时光之轮
- [x] 伞学院 第一季和第二季
- [x] 漫画算法 Python 篇 小灰的算法之旅
- [x] 复变函数与积分变换 第二版 | 强烈推介 | 机械工业
  - 看完不懂的地方建议单独搜索资源搞懂，B 站，知乎都是可以的
  - 将实变函数推广到复数域
  - 常用的积分变换：傅里叶和拉普拉斯变换，建议寻找相关可视化视频，帮助理解
- [x] 吴军数学通识讲义